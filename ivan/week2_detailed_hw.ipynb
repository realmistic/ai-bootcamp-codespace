{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1c1f9e",
   "metadata": {},
   "source": [
    "# Q1: Get data to the fin. agent\n",
    "* Agents SDK OpenAI - create a few agents to read the fin. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1fa6048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.7 environment at: /Users/realmistic/Documents/ai-bootcamp-codespace/.venv\u001b[0m\n",
      "openai                                   1.109.1\n",
      "openai-agents                            0.3.3\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "!uv  pip list | grep openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f75258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Version: 0.3.3\n"
     ]
    }
   ],
   "source": [
    "import agents\n",
    "print(f\"ðŸ“¦ Version: {agents.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5719415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A function calls selfâ€”  \n",
      "Endless mirrors, shrinking down.  \n",
      "Base case breaks the spell.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
    "\n",
    "result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4efaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from agents import function_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8444ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from agents-sdk file\n",
    "def fetch_url(url):\n",
    "    jina_reader_base_url = 'https://r.jina.ai/'\n",
    "    jina_reader_url = jina_reader_base_url + url\n",
    "    response = requests.get(jina_reader_url)\n",
    "    return response.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677be730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.exceptions import RequestException\n",
    "from typing import Optional\n",
    "\n",
    "# @function_tool\n",
    "def fetch_url(url: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetch the textual content of a webpage.\n",
    "\n",
    "    Args:\n",
    "        url (str): The target URL to fetch content from.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The decoded HTML/text content of the fetched page if successful,\n",
    "        or None if an error occurred.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the provided URL is empty or invalid.\n",
    "    \"\"\"\n",
    "    if not url or not isinstance(url, str):\n",
    "        raise ValueError(\"The 'url' parameter must be a non-empty string.\")\n",
    "\n",
    "    jina_reader_base_url = \"https://r.jina.ai/\"\n",
    "    jina_reader_url = jina_reader_base_url + url.lstrip(\"/\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(jina_reader_url, timeout=10)\n",
    "        response.raise_for_status()  # Raises HTTPError for bad status codes\n",
    "        return response.content.decode(\"utf-8\")\n",
    "    except RequestException as e:\n",
    "        # Catch all network-related errors (e.g., ConnectionError, Timeout, HTTPError)\n",
    "        print(f\"Error fetching URL '{jina_reader_url}': {e}\")\n",
    "        return None\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Error decoding response from '{jina_reader_url}'.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad112b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = fetch_url('https://pythoninvest.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a60d130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Use Your Computer to Make Informed Decisions in Stock Trading\n",
      "\n",
      "URL Source: https://pythoninvest.com/\n",
      "\n",
      "Published Time: Tue, 07 Oct 2025 21:34:40 GMT\n",
      "\n",
      "Markdown Content:\n",
      "Use Your Computer to Make Informed Decisions in Stock Trading\n",
      "\n",
      "===============\n",
      "\n",
      "[To main content](https://pythoninvest.com/#t-main-content)\n",
      "\n",
      "*   [Home](https://pythoninvest.com/)\n",
      "*   [News Feed](https://pythoninvest.com/#weekly-fin-news-feed)\n",
      "*   [Blog](https://pythoninvest.com/blog)\n",
      "*   [Course](https://pythoninvest.com/course)\n",
      "*   [Contacts](https://pythoninvest.com/contacts)\n",
      "\n",
      "[Subscribe](https://pythoninvest.com/#popup:subscribe)\n",
      "\n",
      "![Image 1](https://static.tildacdn.net/tild6364-3431-4735-b734-373031313037/Frame_2.svg)\n",
      "\n",
      "![Image 2](https://static.tildacdn.net/tild3563-3230-4562-b337-326333623863/Frame_1.svg)\n",
      "\n",
      "PYTHON\n",
      "\n",
      "[I|]\n",
      "\n",
      "[](https://pythoninvest.com/)\n",
      "\n",
      "[**PYTHON**[|]](https://pythoninvest.com/)\n",
      "\n",
      "*   [Home](https://pythoninvest.com/)\n",
      "*   [News Feed](https://pythoninvest.com/#weekly-fin-news-feed)\n",
      "*   [Blog](https://pythoninvest.com/blog)\n",
      "*   [Course](https://pythoninvest.com/course)\n",
      "*   [Contacts](https://pythoninvest.com/contacts)\n",
      "\n",
      "[Subscribe](https://pythoninvest.com/#popup:subscribe)\n",
      "\n",
      "Use Your Computer to Make Informed Decisions in Stock Trading\n",
      "=============================================================\n",
      "\n",
      "A gentle introduction to stocks market trading, Python programming, analytics, and data visualisation.\n",
      "\n",
      "[Home](https://pythoninvest.com/)\n",
      "\n",
      "[Blog](https://pythoninvest.com/blog)\n",
      "\n",
      "[Course](https://pythoninvest.com/course)\n",
      "\n",
      "[Contacts](https://pythoninvest.com/contacts)\n",
      "\n",
      "![Image 3](https://optim.tildacdn.net/tild3135-6233-4634-b938-656561393733/-/resize/384x/-/format/webp/image_11111.png.webp)\n",
      "\n",
      " Join FREE analytical course by PythonInvest started in May 2025 \n",
      "\n",
      "[Learn more](https://pythoninvest.com/course)\n",
      "\n",
      "What is Python Invest?\n",
      "----------------------\n",
      "\n",
      "\"Every Day, We Decode Financial Markets and Automate with Code.\"\n",
      "\n",
      "![Image 4](https://optim.tildacdn.net/tild3335-3537-4330-a339-656364353130/-/resize/192x/-/format/webp/image_3.png.webp)\n",
      "\n",
      "### Weekly Analytical Review\n",
      "\n",
      "We regularly post fresh market insights and trends by updating the fundamental research Colabs and covering the most liquid stocks.\n",
      "\n",
      "![Image 5](https://optim.tildacdn.net/tild3636-3261-4834-b534-373035353534/-/resize/192x/-/format/webp/image_4.png.webp)\n",
      "\n",
      "### Fundamental Algorithms\n",
      "\n",
      "We post long-reads about the various aspects of financial analysis, trading and portfolio management.\n",
      "\n",
      "![Image 6](https://optim.tildacdn.net/tild3937-3731-4863-b530-383136643936/-/resize/192x/-/format/webp/image_5.png.webp)\n",
      "\n",
      "### Education\n",
      "\n",
      "We publish all the materials on PythonInvest, supporting them with code snippets and code on Github. We develop easy-to-apply Youtube screencasts, and run an instructor-led course.\n",
      "\n",
      "![Image 7](https://optim.tildacdn.net/tild6134-6366-4266-a130-343932633361/-/resize/192x/-/format/webp/image_6.png.webp)\n",
      "\n",
      "### Community\n",
      "\n",
      "We encourage you to join our Telegram channel and subscribe your e-mail to get instant updates. All the materials we publish is up for the discussion on the channel. We're excited to get your feedback and suggestions. Let's rock together!\n",
      "\n",
      "Who might be interested in joining\n",
      "----------------------------------\n",
      "\n",
      "You like puzzles and want to practice your skills in a new area by trying new modelling and visualisation approaches.\n",
      "\n",
      "You work professionally as a Software Engineer and want to get more exposure to the financial markets and analytics.\n",
      "\n",
      "You already make investments in the financial markets and want to get an alternative 'analytical' view on what's going on.\n",
      "\n",
      "### Analysts\n",
      "\n",
      "### Developers\n",
      "\n",
      "### Individual |\n",
      "\n",
      "### Students\n",
      "\n",
      "You want to develop your programming and analytical skills in Python, build your own portfolio and launch a great project.\n",
      "\n",
      "[](https://pythoninvest.com/)\n",
      "\n",
      "Financial News Feed\n",
      "-------------------\n",
      "\n",
      "ML-generated weekly summary of 5000 financial news using OpenAI's ChatGPT summarisation.\n",
      "\n",
      "**NOT AN INVESTMENT ADVICE.**\n",
      "\n",
      "*   FinNews    [Weeks 8 September - 7 October 2025](https://pythoninvest.com/tpost/bjaa36u3j1-weeks-8-september-7-october-2025) Market summary for the weeks 8 September - 7 October 2025  07.10.2025   \n",
      "*   FinNews    [Week 19-25 August 2025](https://pythoninvest.com/tpost/9eglek4ro1-week-19-25-august-2025) Market summary for the week 19 -25 August 2025  25.08.2025   \n",
      "*   FinNews    [Week 29 July - 18 August 2025](https://pythoninvest.com/tpost/95b6dlhkk1-week-29-july-18-august-2025) Market summary for the weeks 29 July- 18 August 2025  18.08.2025   \n",
      "\n",
      "Show More Articles here\n",
      "\n",
      "Show More Articles here\n",
      "\n",
      "Analytical Blog articles\n",
      "------------------------\n",
      "\n",
      "Explore the recent research algorithms, including interactive charts and code on the Github\n",
      "\n",
      "*   Long-read    [Part 17. Stock Screening Using Paid Data](https://pythoninvest.com/long-read/stock-screening-using-paid-data) Stock selection strategy using fundamental analysis and filters on profitability, growth, valuation, and technical indicators.  17.04.2025   \n",
      "*   Long-read    [Part 16. Long-term Impactful Financial News with LLMs](https://pythoninvest.com/long-read/long-term-financial-news-using-llms) Learn about Retrieval-Augmented Generation (RAG), market insights, and innovative approaches to navigate thousands of articles efficiently. Perfect for data enthusiasts and investors looking for actionable intelligence.  25.01.2025   \n",
      "*   Long-read    [Part 15. 2024 U.S. Economy Highlights & Dashboard Insights for Retail Investors](https://pythoninvest.com/long-read/2024-year-wrap-and-automatic-dashboard) Explore key economic trends from 2024, market insights, and predictions for 2025. Learn how the automated dashboard empowers retail investors with real-time data.  27.12.2024   \n",
      "*   Long-read    [Part 14. Exploring Tech Indicators For Stocks and Crypto](https://pythoninvest.com/long-read/tech-indicators-on-crypto-and-stocks) Generating 100 technical indicators using TA-Lib library  01.04.2024   \n",
      "*   Long-read    [Part 13. Leveraging OpenAI's API for Financial News Summarization](https://pythoninvest.com/long-read/chatgpt-api-for-financial-news-summarization) GPT-3.5 and GPT-4 APIs to summarise 5k weekly financial news  10.09.2023   \n",
      "*   Long-read    [Part 12. \"All Weather\" Portfolio with Crypto](https://pythoninvest.com/long-read/all-weather-portfolio-with-crypto) Exploring Ray Dalio's All Weather Portfolio Infused with Cryptocurrencies  23.08.2023   \n",
      "\n",
      "Show More Articles here[Blog with All Articles](https://pythoninvest.com/blog)\n",
      "\n",
      "Show More Articles here[Blog with All Articles](https://pythoninvest.com/blog)\n",
      "\n",
      "About the Author\n",
      "----------------\n",
      "\n",
      "Ivan Brigida\n",
      "\n",
      "[](https://pythoninvest.com/#popup:subscribe)\n",
      "\n",
      "I never planned to be involved in trading. I was taught that markets are generally efficient, making it difficult for a rookie investor to earn money before experienced traders and algorithmic robots capture all the margins. So, I focused on my core job.\n",
      "\n",
      "Everything changed in July 2019 when Revolut announced commission-free stock trading, lowering the barrier to entry to essentially zero. By the end of that year, the market had gained over 28%â€”a historic rise. Then, in early 2020, COVID-19 triggered a 30% market crash in just three months [(Wiki: 2020 stock market crash)](https://en.wikipedia.org/wiki/2020_stock_market_crash). I didnâ€™t believe that fundamental growth factors were broken, so I saw an opportunity.\n",
      "\n",
      "I realized that if I could earn more than my 3% annual mortgage rate, I could increase my total wealth by following a conservative investment strategyâ€”without ever needing to make another early mortgage repayment.\n",
      "\n",
      "With over a decade of experience in business analysis and market research, I wanted to apply my skills to test the financial hypotheses and ideas I encountered in the press.\n",
      "\n",
      "I began investing a significant portion of my free cash flow into the stock market. This not only accelerated my learning but also gave me the satisfaction of building something for myself.\n",
      "\n",
      "Reach Out\n",
      "---------\n",
      "\n",
      "### LinkedIn\n",
      "\n",
      "### Follow me\n",
      "\n",
      "### E-mail\n",
      "\n",
      "### [](https://www.linkedin.com/in/ivan-brigida-0b961319/)[Ivan Brigida](https://www.linkedin.com/in/ivan-brigida-0b961319/)\n",
      "\n",
      "### [info@ pythoninvest.com](mailto:info@pysteps.com)\n",
      "\n",
      "### Sign up for our newsletter to get the latest news\n",
      "\n",
      "Sign up\n",
      "\n",
      "[](https://twitter.com/python_invest)\n",
      "\n",
      "[](https://www.youtube.com/channel/UCZb99NG1IE75c5qH2mCuqVg)\n",
      "\n",
      "[](https://realmistic.medium.com/)\n",
      "\n",
      "[](https://github.com/realmistic?tab=repositories)\n",
      "\n",
      "[![Image 8](https://static.tildacdn.net/tild3732-6461-4139-a162-373433636137/Frame_6.svg)](https://github.com/realmistic/PythonInvest-basic-fin-analysis)\n",
      "\n",
      "[![Image 9](https://static.tildacdn.net/tild3230-3538-4464-b239-393930616163/Frame_5.svg)](https://realmistic.medium.com/)\n",
      "\n",
      "[![Image 10](https://static.tildacdn.net/tild6439-6236-4562-b832-643835346465/Frame_4.svg)](https://www.youtube.com/channel/UCZb99NG1IE75c5qH2mCuqVg)\n",
      "\n",
      "[![Image 11](https://thb.tildacdn.net/tild3833-3535-4238-b730-386132336462/-/resize/20x/138-1388876_cookie-b.png)](https://twitter.com/python_invest)\n",
      "\n",
      "[Home](https://pythoninvest.com/)\n",
      "\n",
      "[Blog](https://pythoninvest.com/blog)\n",
      "\n",
      "[Course](https://pythoninvest.com/course)\n",
      "\n",
      "[Contacts](https://pythoninvest.com/contacts)\n",
      "\n",
      "PYTHON\n",
      "\n",
      "[|]\n",
      "\n",
      "[](https://pythoninvest.com/)\n",
      "\n",
      "[](https://twitter.com/python_invest)\n",
      "\n",
      "[](https://www.youtube.com/channel/UCZb99NG1IE75c5qH2mCuqVg)\n",
      "\n",
      "[](https://realmistic.medium.com/)\n",
      "\n",
      "[](https://github.com/realmistic/PythonInvest-basic-fin-analysis)\n",
      "\n",
      "![Image 12](https://static.tildacdn.net/tild3732-6461-4139-a162-373433636137/Frame_6.svg)\n",
      "\n",
      "![Image 13](https://static.tildacdn.net/tild3230-3538-4464-b239-393930616163/Frame_5.svg)\n",
      "\n",
      "![Image 14](https://static.tildacdn.net/tild6439-6236-4562-b832-643835346465/Frame_4.svg)\n",
      "\n",
      "[![Image 15](https://thb.tildacdn.net/tild3833-3535-4238-b730-386132336462/-/resize/20x/138-1388876_cookie-b.png)](https://twitter.com/python_invest)\n",
      "\n",
      "Â© 2020-2025 PythonInvest\n",
      "\n",
      "All rights reserved \n",
      "\n",
      "[Privacy Policy](https://pythoninvest.com/Privacy)\n",
      "\n",
      "Do you have any questions? Contact us!\n",
      "\n",
      "Send\n",
      "\n",
      "I agree the Terms of Service\n",
      "\n",
      "![Image 16](https://thb.tildacdn.net/tild3938-3266-4363-a338-646135393634/-/empty/image_17.jpg)\n",
      "\n",
      "Please subscribe to receive our new PythonInvest articles first. We will publish a new self-study video course soon.\n",
      "\n",
      "No spam, only useful material.\n",
      "\n",
      "Subscribe\n",
      "\n",
      "Your data has been submitted. Thank you!\n",
      "\n",
      "![Image 17](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=2&event_id=c88537b7-c40a-4b9b-8f82-169b19f4ee7b&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=22153285-0ada-4a8a-bbd4-844aa277262c&pt=Use%20Your%20Computer%20to%20Make%20Informed%20Decisions%20in%20Stock%20Trading&tw_document_href=https%3A%2F%2Fpythoninvest.com%2F&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o8m8k&type=javascript&version=2.3.34)![Image 18](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=2&event_id=c88537b7-c40a-4b9b-8f82-169b19f4ee7b&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=22153285-0ada-4a8a-bbd4-844aa277262c&pt=Use%20Your%20Computer%20to%20Make%20Informed%20Decisions%20in%20Stock%20Trading&tw_document_href=https%3A%2F%2Fpythoninvest.com%2F&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o8m8k&type=javascript&version=2.3.34)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1284d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_agent = Agent(\n",
    "    name='web_agent',\n",
    "    instructions=\"you're a helful assistnat\",\n",
    "    model='gpt-4o-mini',\n",
    "    tools=[function_tool(fetch_url)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee07726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner\n",
    "\n",
    "runner = Runner()\n",
    "\n",
    "question = \"what is this page about? pythoninvest.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ec01702",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await runner.run(web_agent, input=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d61305a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The page at **pythoninvest.com** is focused on helping individuals make informed decisions in stock trading using Python programming. It offers resources related to stock market trading, analytics, and data visualization. Key features include:\n",
      "\n",
      "- **Courses:** Analytical courses that help users learn about stock trading using Python.\n",
      "- **Blog:** Articles covering various aspects of financial analysis and trading strategies.\n",
      "- **Weekly Analytical Review:** Insights and trends in the market.\n",
      "- **Community Engagement:** Opportunities for users to join discussions and share feedback.\n",
      "\n",
      "The site is geared towards analysts, developers, and students looking to enhance their skills in finance and programming.\n"
     ]
    }
   ],
   "source": [
    "print(results.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244a5b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCallItem(agent=Agent(name='web_agent', handoff_description=None, tools=[FunctionTool(name='fetch_url', description='Fetch the textual content of a webpage.', params_json_schema={'properties': {'url': {'description': 'The target URL to fetch content from.', 'title': 'Url', 'type': 'string'}}, 'required': ['url'], 'title': 'fetch_url_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x110577a60>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"you're a helful assistnat\", prompt=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"url\":\"https://pythoninvest.com\"}', call_id='call_1U5bY6tI7hF9KOqBkWPKS78m', name='fetch_url', type='function_call', id='fc_0eb62db030c396d70069053b0e6b3c8194b808733c25d1a5a2', status='completed'), type='tool_call_item'),\n",
       " ToolCallOutputItem(agent=Agent(name='web_agent', handoff_description=None, tools=[FunctionTool(name='fetch_url', description='Fetch the textual content of a webpage.', params_json_schema={'properties': {'url': {'description': 'The target URL to fetch content from.', 'title': 'Url', 'type': 'string'}}, 'required': ['url'], 'title': 'fetch_url_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x110577a60>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"you're a helful assistnat\", prompt=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_1U5bY6tI7hF9KOqBkWPKS78m', 'output': 'Title: Use Your Computer to Make Informed Decisions in Stock Trading\\n\\nURL Source: https://pythoninvest.com/\\n\\nPublished Time: Tue, 07 Oct 2025 21:34:40 GMT\\n\\nMarkdown Content:\\nUse Your Computer to Make Informed Decisions in Stock Trading\\n\\n===============\\n\\n[To main content](https://pythoninvest.com/#t-main-content)\\n\\n*   [Home](https://pythoninvest.com/)\\n*   [News Feed](https://pythoninvest.com/#weekly-fin-news-feed)\\n*   [Blog](https://pythoninvest.com/blog)\\n*   [Course](https://pythoninvest.com/course)\\n*   [Contacts](https://pythoninvest.com/contacts)\\n\\n[Subscribe](https://pythoninvest.com/#popup:subscribe)\\n\\n![Image 1](https://static.tildacdn.net/tild6364-3431-4735-b734-373031313037/Frame_2.svg)\\n\\n![Image 2](https://static.tildacdn.net/tild3563-3230-4562-b337-326333623863/Frame_1.svg)\\n\\nPYTHON\\n\\n[I|]\\n\\n[](https://pythoninvest.com/)\\n\\n[**PYTHON**[|]](https://pythoninvest.com/)\\n\\n*   [Home](https://pythoninvest.com/)\\n*   [News Feed](https://pythoninvest.com/#weekly-fin-news-feed)\\n*   [Blog](https://pythoninvest.com/blog)\\n*   [Course](https://pythoninvest.com/course)\\n*   [Contacts](https://pythoninvest.com/contacts)\\n\\n[Subscribe](https://pythoninvest.com/#popup:subscribe)\\n\\nUse Your Computer to Make Informed Decisions in Stock Trading\\n=============================================================\\n\\nA gentle introduction to stocks market trading, Python programming, analytics, and data visualisation.\\n\\n[Home](https://pythoninvest.com/)\\n\\n[Blog](https://pythoninvest.com/blog)\\n\\n[Course](https://pythoninvest.com/course)\\n\\n[Contacts](https://pythoninvest.com/contacts)\\n\\n![Image 3](https://optim.tildacdn.net/tild3135-6233-4634-b938-656561393733/-/resize/384x/-/format/webp/image_11111.png.webp)\\n\\n Join FREE analytical course by PythonInvest started in May 2025 \\n\\n[Learn more](https://pythoninvest.com/course)\\n\\nWhat is Python Invest?\\n----------------------\\n\\n\"Every Day, We Decode Financial Markets and Automate with Code.\"\\n\\n![Image 4](https://optim.tildacdn.net/tild3335-3537-4330-a339-656364353130/-/resize/192x/-/format/webp/image_3.png.webp)\\n\\n### Weekly Analytical Review\\n\\nWe regularly post fresh market insights and trends by updating the fundamental research Colabs and covering the most liquid stocks.\\n\\n![Image 5](https://optim.tildacdn.net/tild3636-3261-4834-b534-373035353534/-/resize/192x/-/format/webp/image_4.png.webp)\\n\\n### Fundamental Algorithms\\n\\nWe post long-reads about the various aspects of financial analysis, trading and portfolio management.\\n\\n![Image 6](https://optim.tildacdn.net/tild3937-3731-4863-b530-383136643936/-/resize/192x/-/format/webp/image_5.png.webp)\\n\\n### Education\\n\\nWe publish all the materials on PythonInvest, supporting them with code snippets and code on Github. We develop easy-to-apply Youtube screencasts, and run an instructor-led course.\\n\\n![Image 7](https://optim.tildacdn.net/tild6134-6366-4266-a130-343932633361/-/resize/192x/-/format/webp/image_6.png.webp)\\n\\n### Community\\n\\nWe encourage you to join our Telegram channel and subscribe your e-mail to get instant updates. All the materials we publish is up for the discussion on the channel. We\\'re excited to get your feedback and suggestions. Let\\'s rock together!\\n\\nWho might be interested in joining\\n----------------------------------\\n\\nYou like puzzles and want to practice your skills in a new area by trying new modelling and visualisation approaches.\\n\\nYou work professionally as a Software Engineer and want to get more exposure to the financial markets and analytics.\\n\\nYou already make investments in the financial markets and want to get an alternative \\'analytical\\' view on what\\'s going on.\\n\\n### Analysts\\n\\n### Developers\\n\\n### Individual |\\n\\n### Students\\n\\nYou want to develop your programming and analytical skills in Python, build your own portfolio and launch a great project.\\n\\n[](https://pythoninvest.com/)\\n\\nFinancial News Feed\\n-------------------\\n\\nML-generated weekly summary of 5000 financial news using OpenAI\\'s ChatGPT summarisation.\\n\\n**NOT AN INVESTMENT ADVICE.**\\n\\n*   FinNews    [Weeks 8 September - 7 October 2025](https://pythoninvest.com/tpost/bjaa36u3j1-weeks-8-september-7-october-2025) Market summary for the weeks 8 September - 7 October 2025  07.10.2025   \\n*   FinNews    [Week 19-25 August 2025](https://pythoninvest.com/tpost/9eglek4ro1-week-19-25-august-2025) Market summary for the week 19 -25 August 2025  25.08.2025   \\n*   FinNews    [Week 29 July - 18 August 2025](https://pythoninvest.com/tpost/95b6dlhkk1-week-29-july-18-august-2025) Market summary for the weeks 29 July- 18 August 2025  18.08.2025   \\n\\nShow More Articles here\\n\\nShow More Articles here\\n\\nAnalytical Blog articles\\n------------------------\\n\\nExplore the recent research algorithms, including interactive charts and code on the Github\\n\\n*   Long-read    [Part 17. Stock Screening Using Paid Data](https://pythoninvest.com/long-read/stock-screening-using-paid-data) Stock selection strategy using fundamental analysis and filters on profitability, growth, valuation, and technical indicators.  17.04.2025   \\n*   Long-read    [Part 16. Long-term Impactful Financial News with LLMs](https://pythoninvest.com/long-read/long-term-financial-news-using-llms) Learn about Retrieval-Augmented Generation (RAG), market insights, and innovative approaches to navigate thousands of articles efficiently. Perfect for data enthusiasts and investors looking for actionable intelligence.  25.01.2025   \\n*   Long-read    [Part 15. 2024 U.S. Economy Highlights & Dashboard Insights for Retail Investors](https://pythoninvest.com/long-read/2024-year-wrap-and-automatic-dashboard) Explore key economic trends from 2024, market insights, and predictions for 2025. Learn how the automated dashboard empowers retail investors with real-time data.  27.12.2024   \\n*   Long-read    [Part 14. Exploring Tech Indicators For Stocks and Crypto](https://pythoninvest.com/long-read/tech-indicators-on-crypto-and-stocks) Generating 100 technical indicators using TA-Lib library  01.04.2024   \\n*   Long-read    [Part 13. Leveraging OpenAI\\'s API for Financial News Summarization](https://pythoninvest.com/long-read/chatgpt-api-for-financial-news-summarization) GPT-3.5 and GPT-4 APIs to summarise 5k weekly financial news  10.09.2023   \\n*   Long-read    [Part 12. \"All Weather\" Portfolio with Crypto](https://pythoninvest.com/long-read/all-weather-portfolio-with-crypto) Exploring Ray Dalio\\'s All Weather Portfolio Infused with Cryptocurrencies  23.08.2023   \\n\\nShow More Articles here[Blog with All Articles](https://pythoninvest.com/blog)\\n\\nShow More Articles here[Blog with All Articles](https://pythoninvest.com/blog)\\n\\nAbout the Author\\n----------------\\n\\nIvan Brigida\\n\\n[](https://pythoninvest.com/#popup:subscribe)\\n\\nI never planned to be involved in trading. I was taught that markets are generally efficient, making it difficult for a rookie investor to earn money before experienced traders and algorithmic robots capture all the margins. So, I focused on my core job.\\n\\nEverything changed in July 2019 when Revolut announced commission-free stock trading, lowering the barrier to entry to essentially zero. By the end of that year, the market had gained over 28%â€”a historic rise. Then, in early 2020, COVID-19 triggered a 30% market crash in just three months [(Wiki: 2020 stock market crash)](https://en.wikipedia.org/wiki/2020_stock_market_crash). I didnâ€™t believe that fundamental growth factors were broken, so I saw an opportunity.\\n\\nI realized that if I could earn more than my 3% annual mortgage rate, I could increase my total wealth by following a conservative investment strategyâ€”without ever needing to make another early mortgage repayment.\\n\\nWith over a decade of experience in business analysis and market research, I wanted to apply my skills to test the financial hypotheses and ideas I encountered in the press.\\n\\nI began investing a significant portion of my free cash flow into the stock market. This not only accelerated my learning but also gave me the satisfaction of building something for myself.\\n\\nReach Out\\n---------\\n\\n### LinkedIn\\n\\n### Follow me\\n\\n### E-mail\\n\\n### [](https://www.linkedin.com/in/ivan-brigida-0b961319/)[Ivan Brigida](https://www.linkedin.com/in/ivan-brigida-0b961319/)\\n\\n### [info@ pythoninvest.com](mailto:info@pysteps.com)\\n\\n### Sign up for our newsletter to get the latest news\\n\\nSign up\\n\\n[](https://twitter.com/python_invest)\\n\\n[](https://www.youtube.com/channel/UCZb99NG1IE75c5qH2mCuqVg)\\n\\n[](https://realmistic.medium.com/)\\n\\n[](https://github.com/realmistic?tab=repositories)\\n\\n[![Image 8](https://static.tildacdn.net/tild3732-6461-4139-a162-373433636137/Frame_6.svg)](https://github.com/realmistic/PythonInvest-basic-fin-analysis)\\n\\n[![Image 9](https://static.tildacdn.net/tild3230-3538-4464-b239-393930616163/Frame_5.svg)](https://realmistic.medium.com/)\\n\\n[![Image 10](https://static.tildacdn.net/tild6439-6236-4562-b832-643835346465/Frame_4.svg)](https://www.youtube.com/channel/UCZb99NG1IE75c5qH2mCuqVg)\\n\\n[![Image 11](https://thb.tildacdn.net/tild3833-3535-4238-b730-386132336462/-/resize/20x/138-1388876_cookie-b.png)](https://twitter.com/python_invest)\\n\\n[Home](https://pythoninvest.com/)\\n\\n[Blog](https://pythoninvest.com/blog)\\n\\n[Course](https://pythoninvest.com/course)\\n\\n[Contacts](https://pythoninvest.com/contacts)\\n\\nPYTHON\\n\\n[|]\\n\\n[](https://pythoninvest.com/)\\n\\n[](https://twitter.com/python_invest)\\n\\n[](https://www.youtube.com/channel/UCZb99NG1IE75c5qH2mCuqVg)\\n\\n[](https://realmistic.medium.com/)\\n\\n[](https://github.com/realmistic/PythonInvest-basic-fin-analysis)\\n\\n![Image 12](https://static.tildacdn.net/tild3732-6461-4139-a162-373433636137/Frame_6.svg)\\n\\n![Image 13](https://static.tildacdn.net/tild3230-3538-4464-b239-393930616163/Frame_5.svg)\\n\\n![Image 14](https://static.tildacdn.net/tild6439-6236-4562-b832-643835346465/Frame_4.svg)\\n\\n[![Image 15](https://thb.tildacdn.net/tild3833-3535-4238-b730-386132336462/-/resize/20x/138-1388876_cookie-b.png)](https://twitter.com/python_invest)\\n\\nÂ© 2020-2025 PythonInvest\\n\\nAll rights reserved \\n\\n[Privacy Policy](https://pythoninvest.com/Privacy)\\n\\nDo you have any questions? Contact us!\\n\\nSend\\n\\nI agree the Terms of Service\\n\\n![Image 16](https://thb.tildacdn.net/tild3938-3266-4363-a338-646135393634/-/empty/image_17.jpg)\\n\\nPlease subscribe to receive our new PythonInvest articles first. We will publish a new self-study video course soon.\\n\\nNo spam, only useful material.\\n\\nSubscribe\\n\\nYour data has been submitted. Thank you!\\n\\n![Image 17](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=2&event_id=c88537b7-c40a-4b9b-8f82-169b19f4ee7b&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=22153285-0ada-4a8a-bbd4-844aa277262c&pt=Use%20Your%20Computer%20to%20Make%20Informed%20Decisions%20in%20Stock%20Trading&tw_document_href=https%3A%2F%2Fpythoninvest.com%2F&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o8m8k&type=javascript&version=2.3.34)![Image 18](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=2&event_id=c88537b7-c40a-4b9b-8f82-169b19f4ee7b&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=22153285-0ada-4a8a-bbd4-844aa277262c&pt=Use%20Your%20Computer%20to%20Make%20Informed%20Decisions%20in%20Stock%20Trading&tw_document_href=https%3A%2F%2Fpythoninvest.com%2F&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o8m8k&type=javascript&version=2.3.34)\\n', 'type': 'function_call_output'}, output='Title: Use Your Computer to Make Informed Decisions in Stock Trading\\n\\nURL Source: https://pythoninvest.com/\\n\\nPublished Time: Tue, 07 Oct 2025 21:34:40 GMT\\n\\nMarkdown Content:\\nUse Your Computer to Make Informed Decisions in Stock Trading\\n\\n===============\\n\\n[To main content](https://pythoninvest.com/#t-main-content)\\n\\n*   [Home](https://pythoninvest.com/)\\n*   [News Feed](https://pythoninvest.com/#weekly-fin-news-feed)\\n*   [Blog](https://pythoninvest.com/blog)\\n*   [Course](https://pythoninvest.com/course)\\n*   [Contacts](https://pythoninvest.com/contacts)\\n\\n[Subscribe](https://pythoninvest.com/#popup:subscribe)\\n\\n![Image 1](https://static.tildacdn.net/tild6364-3431-4735-b734-373031313037/Frame_2.svg)\\n\\n![Image 2](https://static.tildacdn.net/tild3563-3230-4562-b337-326333623863/Frame_1.svg)\\n\\nPYTHON\\n\\n[I|]\\n\\n[](https://pythoninvest.com/)\\n\\n[**PYTHON**[|]](https://pythoninvest.com/)\\n\\n*   [Home](https://pythoninvest.com/)\\n*   [News Feed](https://pythoninvest.com/#weekly-fin-news-feed)\\n*   [Blog](https://pythoninvest.com/blog)\\n*   [Course](https://pythoninvest.com/course)\\n*   [Contacts](https://pythoninvest.com/contacts)\\n\\n[Subscribe](https://pythoninvest.com/#popup:subscribe)\\n\\nUse Your Computer to Make Informed Decisions in Stock Trading\\n=============================================================\\n\\nA gentle introduction to stocks market trading, Python programming, analytics, and data visualisation.\\n\\n[Home](https://pythoninvest.com/)\\n\\n[Blog](https://pythoninvest.com/blog)\\n\\n[Course](https://pythoninvest.com/course)\\n\\n[Contacts](https://pythoninvest.com/contacts)\\n\\n![Image 3](https://optim.tildacdn.net/tild3135-6233-4634-b938-656561393733/-/resize/384x/-/format/webp/image_11111.png.webp)\\n\\n Join FREE analytical course by PythonInvest started in May 2025 \\n\\n[Learn more](https://pythoninvest.com/course)\\n\\nWhat is Python Invest?\\n----------------------\\n\\n\"Every Day, We Decode Financial Markets and Automate with Code.\"\\n\\n![Image 4](https://optim.tildacdn.net/tild3335-3537-4330-a339-656364353130/-/resize/192x/-/format/webp/image_3.png.webp)\\n\\n### Weekly Analytical Review\\n\\nWe regularly post fresh market insights and trends by updating the fundamental research Colabs and covering the most liquid stocks.\\n\\n![Image 5](https://optim.tildacdn.net/tild3636-3261-4834-b534-373035353534/-/resize/192x/-/format/webp/image_4.png.webp)\\n\\n### Fundamental Algorithms\\n\\nWe post long-reads about the various aspects of financial analysis, trading and portfolio management.\\n\\n![Image 6](https://optim.tildacdn.net/tild3937-3731-4863-b530-383136643936/-/resize/192x/-/format/webp/image_5.png.webp)\\n\\n### Education\\n\\nWe publish all the materials on PythonInvest, supporting them with code snippets and code on Github. We develop easy-to-apply Youtube screencasts, and run an instructor-led course.\\n\\n![Image 7](https://optim.tildacdn.net/tild6134-6366-4266-a130-343932633361/-/resize/192x/-/format/webp/image_6.png.webp)\\n\\n### Community\\n\\nWe encourage you to join our Telegram channel and subscribe your e-mail to get instant updates. All the materials we publish is up for the discussion on the channel. We\\'re excited to get your feedback and suggestions. Let\\'s rock together!\\n\\nWho might be interested in joining\\n----------------------------------\\n\\nYou like puzzles and want to practice your skills in a new area by trying new modelling and visualisation approaches.\\n\\nYou work professionally as a Software Engineer and want to get more exposure to the financial markets and analytics.\\n\\nYou already make investments in the financial markets and want to get an alternative \\'analytical\\' view on what\\'s going on.\\n\\n### Analysts\\n\\n### Developers\\n\\n### Individual |\\n\\n### Students\\n\\nYou want to develop your programming and analytical skills in Python, build your own portfolio and launch a great project.\\n\\n[](https://pythoninvest.com/)\\n\\nFinancial News Feed\\n-------------------\\n\\nML-generated weekly summary of 5000 financial news using OpenAI\\'s ChatGPT summarisation.\\n\\n**NOT AN INVESTMENT ADVICE.**\\n\\n*   FinNews    [Weeks 8 September - 7 October 2025](https://pythoninvest.com/tpost/bjaa36u3j1-weeks-8-september-7-october-2025) Market summary for the weeks 8 September - 7 October 2025  07.10.2025   \\n*   FinNews    [Week 19-25 August 2025](https://pythoninvest.com/tpost/9eglek4ro1-week-19-25-august-2025) Market summary for the week 19 -25 August 2025  25.08.2025   \\n*   FinNews    [Week 29 July - 18 August 2025](https://pythoninvest.com/tpost/95b6dlhkk1-week-29-july-18-august-2025) Market summary for the weeks 29 July- 18 August 2025  18.08.2025   \\n\\nShow More Articles here\\n\\nShow More Articles here\\n\\nAnalytical Blog articles\\n------------------------\\n\\nExplore the recent research algorithms, including interactive charts and code on the Github\\n\\n*   Long-read    [Part 17. Stock Screening Using Paid Data](https://pythoninvest.com/long-read/stock-screening-using-paid-data) Stock selection strategy using fundamental analysis and filters on profitability, growth, valuation, and technical indicators.  17.04.2025   \\n*   Long-read    [Part 16. Long-term Impactful Financial News with LLMs](https://pythoninvest.com/long-read/long-term-financial-news-using-llms) Learn about Retrieval-Augmented Generation (RAG), market insights, and innovative approaches to navigate thousands of articles efficiently. Perfect for data enthusiasts and investors looking for actionable intelligence.  25.01.2025   \\n*   Long-read    [Part 15. 2024 U.S. Economy Highlights & Dashboard Insights for Retail Investors](https://pythoninvest.com/long-read/2024-year-wrap-and-automatic-dashboard) Explore key economic trends from 2024, market insights, and predictions for 2025. Learn how the automated dashboard empowers retail investors with real-time data.  27.12.2024   \\n*   Long-read    [Part 14. Exploring Tech Indicators For Stocks and Crypto](https://pythoninvest.com/long-read/tech-indicators-on-crypto-and-stocks) Generating 100 technical indicators using TA-Lib library  01.04.2024   \\n*   Long-read    [Part 13. Leveraging OpenAI\\'s API for Financial News Summarization](https://pythoninvest.com/long-read/chatgpt-api-for-financial-news-summarization) GPT-3.5 and GPT-4 APIs to summarise 5k weekly financial news  10.09.2023   \\n*   Long-read    [Part 12. \"All Weather\" Portfolio with Crypto](https://pythoninvest.com/long-read/all-weather-portfolio-with-crypto) Exploring Ray Dalio\\'s All Weather Portfolio Infused with Cryptocurrencies  23.08.2023   \\n\\nShow More Articles here[Blog with All Articles](https://pythoninvest.com/blog)\\n\\nShow More Articles here[Blog with All Articles](https://pythoninvest.com/blog)\\n\\nAbout the Author\\n----------------\\n\\nIvan Brigida\\n\\n[](https://pythoninvest.com/#popup:subscribe)\\n\\nI never planned to be involved in trading. I was taught that markets are generally efficient, making it difficult for a rookie investor to earn money before experienced traders and algorithmic robots capture all the margins. So, I focused on my core job.\\n\\nEverything changed in July 2019 when Revolut announced commission-free stock trading, lowering the barrier to entry to essentially zero. By the end of that year, the market had gained over 28%â€”a historic rise. Then, in early 2020, COVID-19 triggered a 30% market crash in just three months [(Wiki: 2020 stock market crash)](https://en.wikipedia.org/wiki/2020_stock_market_crash). I didnâ€™t believe that fundamental growth factors were broken, so I saw an opportunity.\\n\\nI realized that if I could earn more than my 3% annual mortgage rate, I could increase my total wealth by following a conservative investment strategyâ€”without ever needing to make another early mortgage repayment.\\n\\nWith over a decade of experience in business analysis and market research, I wanted to apply my skills to test the financial hypotheses and ideas I encountered in the press.\\n\\nI began investing a significant portion of my free cash flow into the stock market. This not only accelerated my learning but also gave me the satisfaction of building something for myself.\\n\\nReach Out\\n---------\\n\\n### LinkedIn\\n\\n### Follow me\\n\\n### E-mail\\n\\n### [](https://www.linkedin.com/in/ivan-brigida-0b961319/)[Ivan Brigida](https://www.linkedin.com/in/ivan-brigida-0b961319/)\\n\\n### [info@ pythoninvest.com](mailto:info@pysteps.com)\\n\\n### Sign up for our newsletter to get the latest news\\n\\nSign up\\n\\n[](https://twitter.com/python_invest)\\n\\n[](https://www.youtube.com/channel/UCZb99NG1IE75c5qH2mCuqVg)\\n\\n[](https://realmistic.medium.com/)\\n\\n[](https://github.com/realmistic?tab=repositories)\\n\\n[![Image 8](https://static.tildacdn.net/tild3732-6461-4139-a162-373433636137/Frame_6.svg)](https://github.com/realmistic/PythonInvest-basic-fin-analysis)\\n\\n[![Image 9](https://static.tildacdn.net/tild3230-3538-4464-b239-393930616163/Frame_5.svg)](https://realmistic.medium.com/)\\n\\n[![Image 10](https://static.tildacdn.net/tild6439-6236-4562-b832-643835346465/Frame_4.svg)](https://www.youtube.com/channel/UCZb99NG1IE75c5qH2mCuqVg)\\n\\n[![Image 11](https://thb.tildacdn.net/tild3833-3535-4238-b730-386132336462/-/resize/20x/138-1388876_cookie-b.png)](https://twitter.com/python_invest)\\n\\n[Home](https://pythoninvest.com/)\\n\\n[Blog](https://pythoninvest.com/blog)\\n\\n[Course](https://pythoninvest.com/course)\\n\\n[Contacts](https://pythoninvest.com/contacts)\\n\\nPYTHON\\n\\n[|]\\n\\n[](https://pythoninvest.com/)\\n\\n[](https://twitter.com/python_invest)\\n\\n[](https://www.youtube.com/channel/UCZb99NG1IE75c5qH2mCuqVg)\\n\\n[](https://realmistic.medium.com/)\\n\\n[](https://github.com/realmistic/PythonInvest-basic-fin-analysis)\\n\\n![Image 12](https://static.tildacdn.net/tild3732-6461-4139-a162-373433636137/Frame_6.svg)\\n\\n![Image 13](https://static.tildacdn.net/tild3230-3538-4464-b239-393930616163/Frame_5.svg)\\n\\n![Image 14](https://static.tildacdn.net/tild6439-6236-4562-b832-643835346465/Frame_4.svg)\\n\\n[![Image 15](https://thb.tildacdn.net/tild3833-3535-4238-b730-386132336462/-/resize/20x/138-1388876_cookie-b.png)](https://twitter.com/python_invest)\\n\\nÂ© 2020-2025 PythonInvest\\n\\nAll rights reserved \\n\\n[Privacy Policy](https://pythoninvest.com/Privacy)\\n\\nDo you have any questions? Contact us!\\n\\nSend\\n\\nI agree the Terms of Service\\n\\n![Image 16](https://thb.tildacdn.net/tild3938-3266-4363-a338-646135393634/-/empty/image_17.jpg)\\n\\nPlease subscribe to receive our new PythonInvest articles first. We will publish a new self-study video course soon.\\n\\nNo spam, only useful material.\\n\\nSubscribe\\n\\nYour data has been submitted. Thank you!\\n\\n![Image 17](https://t.co/i/adsct?bci=3&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=2&event_id=c88537b7-c40a-4b9b-8f82-169b19f4ee7b&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=22153285-0ada-4a8a-bbd4-844aa277262c&pt=Use%20Your%20Computer%20to%20Make%20Informed%20Decisions%20in%20Stock%20Trading&tw_document_href=https%3A%2F%2Fpythoninvest.com%2F&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o8m8k&type=javascript&version=2.3.34)![Image 18](https://analytics.twitter.com/i/adsct?bci=3&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=2&event_id=c88537b7-c40a-4b9b-8f82-169b19f4ee7b&events=%5B%5B%22pageview%22%2C%7B%7D%5D%5D&integration=advertiser&p_id=Twitter&p_user_id=0&pl_id=22153285-0ada-4a8a-bbd4-844aa277262c&pt=Use%20Your%20Computer%20to%20Make%20Informed%20Decisions%20in%20Stock%20Trading&tw_document_href=https%3A%2F%2Fpythoninvest.com%2F&tw_iframe_status=0&tw_order_quantity=0&tw_sale_amount=0&txn_id=o8m8k&type=javascript&version=2.3.34)\\n', type='tool_call_output_item'),\n",
       " MessageOutputItem(agent=Agent(name='web_agent', handoff_description=None, tools=[FunctionTool(name='fetch_url', description='Fetch the textual content of a webpage.', params_json_schema={'properties': {'url': {'description': 'The target URL to fetch content from.', 'title': 'Url', 'type': 'string'}}, 'required': ['url'], 'title': 'fetch_url_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x110577a60>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"you're a helful assistnat\", prompt=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_0eb62db030c396d70069053b10d1748194b894f4a1df4d14b1', content=[ResponseOutputText(annotations=[], text='The page at **pythoninvest.com** is focused on helping individuals make informed decisions in stock trading using Python programming. It offers resources related to stock market trading, analytics, and data visualization. Key features include:\\n\\n- **Courses:** Analytical courses that help users learn about stock trading using Python.\\n- **Blog:** Articles covering various aspects of financial analysis and trading strategies.\\n- **Weekly Analytical Review:** Insights and trends in the market.\\n- **Community Engagement:** Opportunities for users to join discussions and share feedback.\\n\\nThe site is geared towards analysts, developers, and students looking to enhance their skills in finance and programming.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), type='message_output_item')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.new_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e00dd1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f0d3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @function_tool\n",
    "def get_eps_trend(ticker: str) -> dict:\n",
    "    \"\"\"\n",
    "      Get the EPS (Earnings Per Share) trend for a given stock ticker.\n",
    "      \n",
    "      Args:\n",
    "          ticker: Stock ticker symbol (e.g., 'AAPL', 'GOOGL', 'MSFT')\n",
    "      \n",
    "      Returns:\n",
    "          Dictionary containing EPS trend data for the specified ticker\n",
    "      \"\"\"\n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    result = ticker_obj.get_eps_trend()\n",
    "    # Convert DataFrame to dict if needed\n",
    "    if isinstance(result, pd.DataFrame):\n",
    "        return result.to_dict(orient='records')  # List of dicts\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b3b24c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'current': 0.43803, '7daysAgo': 0.44158, '30daysAgo': 0.46205, '60daysAgo': 0.46042, '90daysAgo': 0.4721}, {'current': 0.44611, '7daysAgo': 0.44842, '30daysAgo': 0.45767, '60daysAgo': 0.45152, '90daysAgo': 0.45152}, {'current': 1.65422, '7daysAgo': 1.69074, '30daysAgo': 1.68203, '60daysAgo': 1.6747, '90daysAgo': 1.67603}, {'current': 2.25553, '7daysAgo': 2.32696, '30daysAgo': 2.38618, '60daysAgo': 2.36581, '90daysAgo': 2.40581}]\n"
     ]
    }
   ],
   "source": [
    "r = get_eps_trend(\"TSLA\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baf0717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we need WebSearch \n",
    "from agents import WebSearchTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "175b5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_agent = Agent(\n",
    "    name='stock_agent',\n",
    "    instructions=\"you're a helful assistant. Try to use all defined tools before going into the WebSearchTool\",\n",
    "    model='gpt-4o-mini',\n",
    "    tools=[ \n",
    "            # WebSearchTool(), \n",
    "           function_tool(get_eps_trend)] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b1300d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = await runner.run(stock_agent, \n",
    "#                            input=\"get me the eps trend for TSLA and the latest earnings call date and results, news sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b186866d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The page at **pythoninvest.com** is focused on helping individuals make informed decisions in stock trading using Python programming. It offers resources related to stock market trading, analytics, and data visualization. Key features include:\n",
      "\n",
      "- **Courses:** Analytical courses that help users learn about stock trading using Python.\n",
      "- **Blog:** Articles covering various aspects of financial analysis and trading strategies.\n",
      "- **Weekly Analytical Review:** Insights and trends in the market.\n",
      "- **Community Engagement:** Opportunities for users to join discussions and share feedback.\n",
      "\n",
      "The site is geared towards analysts, developers, and students looking to enhance their skills in finance and programming.\n"
     ]
    }
   ],
   "source": [
    "print(results.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee36c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def get_eps_trend(ticker: str) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get the EPS (Earnings Per Share) trend for a given stock ticker.\n",
    "\n",
    "    Args:\n",
    "        ticker: Stock ticker symbol (e.g., 'AAPL', 'GOOGL', 'MSFT')\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with EPS trend data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ticker_obj = yf.Ticker(ticker)\n",
    "        result = ticker_obj.get_eps_trend()\n",
    "\n",
    "        if isinstance(result, pd.DataFrame):\n",
    "            if result.empty:\n",
    "                return {\"error\": f\"No EPS trend data available for {ticker}\"}\n",
    "            return {\"ticker\": ticker, \"data\": result.to_dict(orient='records')}\n",
    "        return {\"ticker\": ticker, \"data\": result}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to get EPS trend for {ticker}: {str(e)}\"}\n",
    "\n",
    "def get_earnings_dates(ticker: str) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get earnings call dates for a stock ticker. The function all returns the expected EPS, the actual EPS, and the surprise percentage.\n",
    "    It has stats from many quarters and years.\n",
    "    It also returns the next earnings call date.\n",
    "    Args:\n",
    "        ticker: Stock ticker symbol\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with earnings dates\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ticker_obj = yf.Ticker(ticker)\n",
    "        result = ticker_obj.get_earnings_dates()\n",
    "\n",
    "        # if dataframe - main case\n",
    "        if isinstance(result, pd.DataFrame):\n",
    "            if result.empty:\n",
    "                return {\"error\": f\"No earnings data available for {ticker}\"}\n",
    "        \n",
    "            # Include the index (dates) as a column before converting to dict\n",
    "            result = result.reset_index().rename(columns={\"index\": \"date\"})\n",
    "\n",
    "            # return good stats\n",
    "            return {\"ticker\": ticker, \"data\": result.to_dict(orient='records'), \"date_of_run\": str(datetime.now(timezone.utc).strftime(\"%Y-%m-%d\"))}\n",
    "        \n",
    "        # return {\"ticker\": ticker, \"data\": result.to_dict(orient='records'), \"date_of_run\": str(datetime.now(timezone.utc).strftime(\"%Y-%m-%d\"))}\n",
    "        return {\"error\":\"bad format - API returned not a dictionary\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to get earnings dates for {ticker}: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe21e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ticker': 'TSLA', 'data': [{'Earnings Date': Timestamp('2026-01-28 15:00:00-0500', tz='America/New_York'), 'EPS Estimate': 0.44, 'Reported EPS': nan, 'Surprise(%)': nan}, {'Earnings Date': Timestamp('2025-10-22 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.56, 'Reported EPS': 0.5, 'Surprise(%)': -10.53}, {'Earnings Date': Timestamp('2025-07-23 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.4, 'Reported EPS': 0.4, 'Surprise(%)': -0.97}, {'Earnings Date': Timestamp('2025-04-22 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.41, 'Reported EPS': 0.27, 'Surprise(%)': -34.89}, {'Earnings Date': Timestamp('2025-01-29 16:00:00-0500', tz='America/New_York'), 'EPS Estimate': 0.77, 'Reported EPS': 0.73, 'Surprise(%)': -4.83}, {'Earnings Date': Timestamp('2024-10-23 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.5, 'Reported EPS': 0.62, 'Surprise(%)': 24.76}, {'Earnings Date': Timestamp('2024-07-23 20:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.62, 'Reported EPS': 0.52, 'Surprise(%)': -16.15}, {'Earnings Date': Timestamp('2024-04-23 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.49, 'Reported EPS': 0.45, 'Surprise(%)': -8.14}, {'Earnings Date': Timestamp('2024-01-24 16:00:00-0500', tz='America/New_York'), 'EPS Estimate': 0.74, 'Reported EPS': 0.71, 'Surprise(%)': -4.1}, {'Earnings Date': Timestamp('2023-10-18 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.73, 'Reported EPS': 0.66, 'Surprise(%)': -9.81}, {'Earnings Date': Timestamp('2023-07-19 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.82, 'Reported EPS': 0.91, 'Surprise(%)': 11.12}, {'Earnings Date': Timestamp('2023-04-19 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.85, 'Reported EPS': 0.85, 'Surprise(%)': -0.43}, {'Earnings Date': Timestamp('2023-01-25 16:00:00-0500', tz='America/New_York'), 'EPS Estimate': 1.11, 'Reported EPS': 1.19, 'Surprise(%)': 7.2}, {'Earnings Date': Timestamp('2022-10-19 17:00:00-0400', tz='America/New_York'), 'EPS Estimate': 1.0, 'Reported EPS': 1.05, 'Surprise(%)': 5.23}, {'Earnings Date': Timestamp('2022-07-20 17:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.6, 'Reported EPS': 0.76, 'Surprise(%)': 26.89}, {'Earnings Date': Timestamp('2022-04-20 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.75, 'Reported EPS': 1.07, 'Surprise(%)': 42.31}, {'Earnings Date': Timestamp('2022-01-26 16:00:00-0500', tz='America/New_York'), 'EPS Estimate': 0.79, 'Reported EPS': 0.85, 'Surprise(%)': 6.88}, {'Earnings Date': Timestamp('2021-10-20 15:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.54, 'Reported EPS': 0.62, 'Surprise(%)': 15.22}, {'Earnings Date': Timestamp('2021-07-26 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.32, 'Reported EPS': 0.48, 'Surprise(%)': 49.86}, {'Earnings Date': Timestamp('2021-04-26 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.26, 'Reported EPS': 0.31, 'Surprise(%)': 19.42}, {'Earnings Date': Timestamp('2021-01-27 16:00:00-0500', tz='America/New_York'), 'EPS Estimate': 0.35, 'Reported EPS': 0.27, 'Surprise(%)': -23.91}, {'Earnings Date': Timestamp('2020-10-21 18:00:00-0400', tz='America/New_York'), 'EPS Estimate': 0.2, 'Reported EPS': 0.25, 'Surprise(%)': 25.78}, {'Earnings Date': Timestamp('2020-07-22 16:00:00-0400', tz='America/New_York'), 'EPS Estimate': -0.01, 'Reported EPS': 0.15, 'Surprise(%)': 1460.77}, {'Earnings Date': Timestamp('2020-04-29 12:00:00-0400', tz='America/New_York'), 'EPS Estimate': -0.01, 'Reported EPS': 0.08, 'Surprise(%)': 650.29}, {'Earnings Date': Timestamp('2020-01-29 16:00:00-0500', tz='America/New_York'), 'EPS Estimate': 0.12, 'Reported EPS': 0.14, 'Surprise(%)': 17.76}], 'date_of_run': '2025-10-31'}\n"
     ]
    }
   ],
   "source": [
    "r = get_earnings_dates(\"TSLA\")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa04ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent\n",
    "stock_agent = Agent(\n",
    "    name=\"Stock Analyst\",\n",
    "    instructions=\"\"\"You are a stock market analyst. \n",
    "When tools return data, summarize it clearly for the user.\n",
    "I need to understand the EPS growth trend and YoY, the surprise on average over the last years (CAGR) and last 4 quarters.\n",
    "When is the next earnings call date (usually the date in the earnings calendar first/last, after than the current date)? \n",
    "If a tool returns an error, explain it and don't retry the same thing repeatedly.\n",
    "Use Earnings Dates function first, as it contains more data.\n",
    "\n",
    "If there is an error from an API - show the error to the user.\"\"\",\n",
    "    tools=[\n",
    "        # WebSearchTool(), \n",
    "        function_tool(get_eps_trend),\n",
    "        function_tool(get_earnings_dates)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b54be7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "tada"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(\"tada\"))  # ensures full rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71100e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "------------------------------------------------------------------------------------------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "--- Analyzing ticker: META ---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hereâ€™s a summary of the EPS (Earnings Per Share) growth trend, recent earnings surprises, and the next earnings call for META:\n",
       "\n",
       "### EPS Growth Trend (Year-over-Year and Latest Quarters)\n",
       "- EPS has shown strong growth over the recent quarters and years:\n",
       "    - Last four quarters (actual EPS, newest to oldest): 7.25, 7.14, 6.43, 8.02\n",
       "    - Prior year four quarters: 6.03, 5.16, 4.71, 5.33\n",
       "\n",
       "- YoY comparison (using most recent comparable quarters):\n",
       "    - EPS has grown significantly versus the prior year. For example: \n",
       "        - Q3: 7.25 (2025) vs. 6.03 (2024) â†’ ~20% YoY growth\n",
       "        - Q2: 7.14 (2025) vs. 5.16 (2024) â†’ ~38% YoY growth\n",
       "        - Q1: 6.43 (2025) vs. 4.71 (2024) â†’ ~37% YoY growth\n",
       "        - Q4: 8.02 (2025) vs. 5.33 (2024) â†’ ~51% YoY growth\n",
       "\n",
       "### EPS Surprise (Average)\n",
       "- Last 4 quarters:\n",
       "    - 8.66%, 21.82%, 23.53%, 19.00%\n",
       "    - Average EPS surprise: ~18.75%\n",
       "- Recent multi-year trend:\n",
       "    - Last 3 years: EPS surprises have varied, but have averaged in the high single-digits to low double-digits, with some volatility (range from -20% to over +40%).\n",
       "\n",
       "### Next Earnings Call\n",
       "- The next scheduled earnings call for META is on January 28, 2026.\n",
       "\n",
       "If you need historical CAGR calculations or more detail, let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "=========================================================================================="
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using display to ensure full output rendering in Jupyter\n",
    "\n",
    "for ticker in [\"META\"]:\n",
    "# ['AMZN', \"AAPL\", \"GOOGL\", \"META\", \"MSFT\"]:\n",
    "    display(Markdown(\"---\"*30))\n",
    "    display(Markdown(f\"--- Analyzing ticker: {ticker} ---\"))\n",
    "\n",
    "    results = await Runner.run(\n",
    "        stock_agent,\n",
    "        input=f\"get me the eps trend for {ticker} and the latest earnings call date\",\n",
    "        max_turns=20  # Increase max turns\n",
    "    )\n",
    "\n",
    "    display(Markdown(results.final_output))\n",
    "    display(Markdown(\"===\"*30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4454c0",
   "metadata": {},
   "source": [
    "# Q2: Finance news db & chunking strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccd1b45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-10-31'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "datetime.now(timezone.utc).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3da5f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-31T22:41:35.182+00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "# The exact time of running the Colab (in UTC, timezone-aware)\n",
    "now_right_format = datetime.now(timezone.utc).isoformat(timespec='milliseconds')\n",
    "print(now_right_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f5acf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-31T22:41:35.188Z\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "# The exact time of running the Colab\n",
    "now = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')  # RFC3339 format\n",
    "now_right_format = now\n",
    "print(now_right_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d469a3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# check the API KEY is imported correctly from the .envrc file\n",
    "print(len(os.getenv('POLYGON_API_KEY')))\n",
    "\n",
    "POLYGON_API_KEY = os.getenv('POLYGON_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e48b32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://polygon.io/docs/stocks/get_v2_reference_news\n",
    "# https://polygon.io/blog/api-pagination-patterns/\n",
    "# API CALL : # https://api.polygon.io/v2/reference/news?order=desc&limit=1000&sort=published_utc&apiKey=<your key> or POLYGON_API_KEY\n",
    "      # need to get 200 OK status\n",
    "\n",
    "# retrieve max 1000 news via one API call\n",
    "def get_one_chunk_of_news_polygon_io(api_key = POLYGON_API_KEY, news_limit=1000, max_date = now_right_format):\n",
    "  url = f\"https://api.polygon.io/v2/reference/news?order=desc&limit={news_limit}&sort=published_utc&published_utc.lt={max_date}&apiKey={api_key}\"\n",
    "\n",
    "  # https://www.nylas.com/blog/use-python-requests-module-rest-apis/ - Python for rest APIs\n",
    "  # try/catch for HTTP requests: https://stackoverflow.com/questions/16511337/correct-way-to-try-except-using-python-requests-module\n",
    "  try:\n",
    "      print(f'trying the API call : {url}')\n",
    "      r = requests.get(url, timeout=3)\n",
    "      r.raise_for_status()\n",
    "  except requests.exceptions.HTTPError as errh:\n",
    "      print (\"Http Error:\",errh)\n",
    "  except requests.exceptions.ConnectionError as errc:\n",
    "      print (\"Error Connecting:\",errc)\n",
    "  except requests.exceptions.Timeout as errt:\n",
    "      print (\"Timeout Error:\",errt)\n",
    "  except requests.exceptions.RequestException as err:\n",
    "      print (\"OOps: Something Else\",err)\n",
    "\n",
    "  data = r.json()\n",
    "\n",
    "\n",
    "  # Check if 'results' key exists in the response\n",
    "  if 'results' in data:\n",
    "      # If it exists, proceed with normalization\n",
    "      df_nested_list = pd.json_normalize(data, record_path=['results'])\n",
    "  else:\n",
    "      # If not, print the response keys for debugging and create an empty DataFrame\n",
    "      print(f\"The 'results' key was not found in the response. Available keys are: {data.keys()}\")\n",
    "      df_nested_list = pd.DataFrame() # or handle it differently based on the new structure\n",
    "\n",
    "  return df_nested_list\n",
    "\n",
    "  # OLD CODE: # https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8\n",
    "  # df_nested_list = pd.json_normalize(data, record_path =['results'])\n",
    "  # print(f'Retrieved : {len(df_nested_list)} news; min_datetime = {df_nested_list.published_utc.min()}, max_datetime = {df_nested_list.published_utc.max()}')\n",
    "  # return df_nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e5da6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_news(api_calls_left = 5, api_key = POLYGON_API_KEY, news_limit=1000, max_date = now_right_format):\n",
    "  all_news = None\n",
    "  for i in range(api_calls_left):\n",
    "    cur = get_one_chunk_of_news_polygon_io(api_key = api_key, news_limit = news_limit, max_date = max_date)\n",
    "    if all_news is None:\n",
    "      all_news = cur\n",
    "    else:\n",
    "      all_news = pd.concat([all_news,cur], ignore_index=True, axis=0) #stacking dataframes\n",
    "\n",
    "    max_date = cur.published_utc.min() #update max_date of the news\n",
    "  return all_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b22ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying the API call : https://api.polygon.io/v2/reference/news?order=desc&limit=1000&sort=published_utc&published_utc.lt=2025-10-31T22:41:35.188Z&apiKey=ChTGkHcZ52m1DGD_KCgVOUwbV3iJ61_X\n",
      "trying the API call : https://api.polygon.io/v2/reference/news?order=desc&limit=1000&sort=published_utc&published_utc.lt=2025-10-27T20:00:00Z&apiKey=ChTGkHcZ52m1DGD_KCgVOUwbV3iJ61_X\n",
      "trying the API call : https://api.polygon.io/v2/reference/news?order=desc&limit=1000&sort=published_utc&published_utc.lt=2025-10-22T13:00:00Z&apiKey=ChTGkHcZ52m1DGD_KCgVOUwbV3iJ61_X\n",
      "trying the API call : https://api.polygon.io/v2/reference/news?order=desc&limit=1000&sort=published_utc&published_utc.lt=2025-10-16T15:14:04Z&apiKey=ChTGkHcZ52m1DGD_KCgVOUwbV3iJ61_X\n",
      "trying the API call : https://api.polygon.io/v2/reference/news?order=desc&limit=1000&sort=published_utc&published_utc.lt=2025-10-10T21:33:22Z&apiKey=ChTGkHcZ52m1DGD_KCgVOUwbV3iJ61_X\n"
     ]
    }
   ],
   "source": [
    "# 5 calls per minute limit for a free account - all recent news (5000)\n",
    "all_news = get_all_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a572fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>published_utc</th>\n",
       "      <th>article_url</th>\n",
       "      <th>tickers</th>\n",
       "      <th>image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>insights</th>\n",
       "      <th>publisher.name</th>\n",
       "      <th>publisher.homepage_url</th>\n",
       "      <th>publisher.logo_url</th>\n",
       "      <th>publisher.favicon_url</th>\n",
       "      <th>amp_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fbd05842ba119aa51c71df671c546137b0c395b70d735a...</td>\n",
       "      <td>JSPR DEADLINE: ROSEN, SKILLED INVESTOR COUNSEL...</td>\n",
       "      <td>Rosen Law Firm</td>\n",
       "      <td>2025-10-31T21:38:00Z</td>\n",
       "      <td>https://www.globenewswire.com/news-release/202...</td>\n",
       "      <td>[JSPR, JSPRW]</td>\n",
       "      <td>https://ml.globenewswire.com/Resource/Download...</td>\n",
       "      <td>Rosen Law Firm is pursuing a securities class ...</td>\n",
       "      <td>[securities lawsuit, class action, manufacturi...</td>\n",
       "      <td>[{'ticker': 'JSPR', 'sentiment': 'negative', '...</td>\n",
       "      <td>GlobeNewswire Inc.</td>\n",
       "      <td>https://www.globenewswire.com</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/logos...</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/favic...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1b26ee6b521fb3390e0852ddb9053d910e58f56a6165af...</td>\n",
       "      <td>Capital Group Canada Announces Estimated 2025 ...</td>\n",
       "      <td>Prnewswire</td>\n",
       "      <td>2025-10-31T21:30:00Z</td>\n",
       "      <td>https://www.benzinga.com/pressreleases/25/10/n...</td>\n",
       "      <td>[CGCB]</td>\n",
       "      <td>https://www.benzinga.com/next-assets/images/be...</td>\n",
       "      <td>Capital Group Canada released estimated annual...</td>\n",
       "      <td>[ETFs, capital gains, distributions, tax year,...</td>\n",
       "      <td>[{'ticker': 'CGCB', 'sentiment': 'neutral', 's...</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>https://www.benzinga.com/</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/logos...</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/favic...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c45000e9357bab55292e000cb8d97bf92de28278e5f1d6...</td>\n",
       "      <td>Caliber Launches Noteholder Debt-to-Equity Con...</td>\n",
       "      <td>Caliber Investor Relations</td>\n",
       "      <td>2025-10-31T21:25:00Z</td>\n",
       "      <td>https://www.globenewswire.com/news-release/202...</td>\n",
       "      <td>[CWD, GLNK]</td>\n",
       "      <td>https://ml.globenewswire.com/Resource/Download...</td>\n",
       "      <td>Caliber announced a voluntary Noteholder Conve...</td>\n",
       "      <td>[debt conversion, equity, financial restructur...</td>\n",
       "      <td>[{'ticker': 'CWD', 'sentiment': 'positive', 's...</td>\n",
       "      <td>GlobeNewswire Inc.</td>\n",
       "      <td>https://www.globenewswire.com</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/logos...</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/favic...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f454b54fa7f7c606181104a3d8c08f9b0d626795c35daa...</td>\n",
       "      <td>Gran Tierra Announces Confirmation with Respec...</td>\n",
       "      <td>Globe Newswire</td>\n",
       "      <td>2025-10-31T21:21:00Z</td>\n",
       "      <td>https://www.benzinga.com/pressreleases/25/10/g...</td>\n",
       "      <td>[GTE]</td>\n",
       "      <td>https://www.benzinga.com/next-assets/images/be...</td>\n",
       "      <td>Gran Tierra Energy confirmed compliance with p...</td>\n",
       "      <td>[acquisition, takeover, scheme of arrangement,...</td>\n",
       "      <td>[{'ticker': 'GTE', 'sentiment': 'neutral', 'se...</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>https://www.benzinga.com/</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/logos...</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/favic...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5bf11b738ec7881ca1e4bb34979062f1ed853d87eaa3ac...</td>\n",
       "      <td>Dynamix Corporation III Completes $201.25 Mill...</td>\n",
       "      <td>Globe Newswire</td>\n",
       "      <td>2025-10-31T21:13:50Z</td>\n",
       "      <td>https://www.benzinga.com/pressreleases/25/10/g...</td>\n",
       "      <td>[COHN, ETHM, ETHMU, ETHMW]</td>\n",
       "      <td>https://www.benzinga.com/next-assets/images/be...</td>\n",
       "      <td>Dynamix Corporation III successfully completed...</td>\n",
       "      <td>[IPO, SPAC, Nasdaq, energy infrastructure, dig...</td>\n",
       "      <td>[{'ticker': 'COHN', 'sentiment': 'neutral', 's...</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>https://www.benzinga.com/</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/logos...</td>\n",
       "      <td>https://s3.polygon.io/public/assets/news/favic...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  fbd05842ba119aa51c71df671c546137b0c395b70d735a...   \n",
       "1  1b26ee6b521fb3390e0852ddb9053d910e58f56a6165af...   \n",
       "2  c45000e9357bab55292e000cb8d97bf92de28278e5f1d6...   \n",
       "3  f454b54fa7f7c606181104a3d8c08f9b0d626795c35daa...   \n",
       "4  5bf11b738ec7881ca1e4bb34979062f1ed853d87eaa3ac...   \n",
       "\n",
       "                                               title  \\\n",
       "0  JSPR DEADLINE: ROSEN, SKILLED INVESTOR COUNSEL...   \n",
       "1  Capital Group Canada Announces Estimated 2025 ...   \n",
       "2  Caliber Launches Noteholder Debt-to-Equity Con...   \n",
       "3  Gran Tierra Announces Confirmation with Respec...   \n",
       "4  Dynamix Corporation III Completes $201.25 Mill...   \n",
       "\n",
       "                       author         published_utc  \\\n",
       "0              Rosen Law Firm  2025-10-31T21:38:00Z   \n",
       "1                  Prnewswire  2025-10-31T21:30:00Z   \n",
       "2  Caliber Investor Relations  2025-10-31T21:25:00Z   \n",
       "3              Globe Newswire  2025-10-31T21:21:00Z   \n",
       "4              Globe Newswire  2025-10-31T21:13:50Z   \n",
       "\n",
       "                                         article_url  \\\n",
       "0  https://www.globenewswire.com/news-release/202...   \n",
       "1  https://www.benzinga.com/pressreleases/25/10/n...   \n",
       "2  https://www.globenewswire.com/news-release/202...   \n",
       "3  https://www.benzinga.com/pressreleases/25/10/g...   \n",
       "4  https://www.benzinga.com/pressreleases/25/10/g...   \n",
       "\n",
       "                      tickers  \\\n",
       "0               [JSPR, JSPRW]   \n",
       "1                      [CGCB]   \n",
       "2                 [CWD, GLNK]   \n",
       "3                       [GTE]   \n",
       "4  [COHN, ETHM, ETHMU, ETHMW]   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://ml.globenewswire.com/Resource/Download...   \n",
       "1  https://www.benzinga.com/next-assets/images/be...   \n",
       "2  https://ml.globenewswire.com/Resource/Download...   \n",
       "3  https://www.benzinga.com/next-assets/images/be...   \n",
       "4  https://www.benzinga.com/next-assets/images/be...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Rosen Law Firm is pursuing a securities class ...   \n",
       "1  Capital Group Canada released estimated annual...   \n",
       "2  Caliber announced a voluntary Noteholder Conve...   \n",
       "3  Gran Tierra Energy confirmed compliance with p...   \n",
       "4  Dynamix Corporation III successfully completed...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [securities lawsuit, class action, manufacturi...   \n",
       "1  [ETFs, capital gains, distributions, tax year,...   \n",
       "2  [debt conversion, equity, financial restructur...   \n",
       "3  [acquisition, takeover, scheme of arrangement,...   \n",
       "4  [IPO, SPAC, Nasdaq, energy infrastructure, dig...   \n",
       "\n",
       "                                            insights      publisher.name  \\\n",
       "0  [{'ticker': 'JSPR', 'sentiment': 'negative', '...  GlobeNewswire Inc.   \n",
       "1  [{'ticker': 'CGCB', 'sentiment': 'neutral', 's...            Benzinga   \n",
       "2  [{'ticker': 'CWD', 'sentiment': 'positive', 's...  GlobeNewswire Inc.   \n",
       "3  [{'ticker': 'GTE', 'sentiment': 'neutral', 'se...            Benzinga   \n",
       "4  [{'ticker': 'COHN', 'sentiment': 'neutral', 's...            Benzinga   \n",
       "\n",
       "          publisher.homepage_url  \\\n",
       "0  https://www.globenewswire.com   \n",
       "1      https://www.benzinga.com/   \n",
       "2  https://www.globenewswire.com   \n",
       "3      https://www.benzinga.com/   \n",
       "4      https://www.benzinga.com/   \n",
       "\n",
       "                                  publisher.logo_url  \\\n",
       "0  https://s3.polygon.io/public/assets/news/logos...   \n",
       "1  https://s3.polygon.io/public/assets/news/logos...   \n",
       "2  https://s3.polygon.io/public/assets/news/logos...   \n",
       "3  https://s3.polygon.io/public/assets/news/logos...   \n",
       "4  https://s3.polygon.io/public/assets/news/logos...   \n",
       "\n",
       "                               publisher.favicon_url amp_url  \n",
       "0  https://s3.polygon.io/public/assets/news/favic...     NaN  \n",
       "1  https://s3.polygon.io/public/assets/news/favic...     NaN  \n",
       "2  https://s3.polygon.io/public/assets/news/favic...     NaN  \n",
       "3  https://s3.polygon.io/public/assets/news/favic...     NaN  \n",
       "4  https://s3.polygon.io/public/assets/news/favic...     NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16aa522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'fbd05842ba119aa51c71df671c546137b0c395b70d735a94724698973036bd88', 'title': 'JSPR DEADLINE: ROSEN, SKILLED INVESTOR COUNSEL, Encourages Jasper Therapeutics, Inc. Investors with Losses in Excess of $100K to Secure Counsel Before Important Deadline in Securities Class Action â€“ JSPR', 'author': 'Rosen Law Firm', 'published_utc': '2025-10-31T21:38:00Z', 'article_url': 'https://www.globenewswire.com/news-release/2025/10/31/3178678/673/en/JSPR-DEADLINE-ROSEN-SKILLED-INVESTOR-COUNSEL-Encourages-Jasper-Therapeutics-Inc-Investors-with-Losses-in-Excess-of-100K-to-Secure-Counsel-Before-Important-Deadline-in-Securities-Cl.html', 'tickers': ['JSPR', 'JSPRW'], 'image_url': 'https://ml.globenewswire.com/Resource/Download/745335af-3a3a-4fb5-84c0-fdedc9adf092', 'description': 'Rosen Law Firm is pursuing a securities class action lawsuit against Therapeutics for allegedly making false and misleading statements about manufacturing controls and product prospects during the period of November 30, 2023 to July 3, 2025.', 'keywords': ['securities lawsuit', 'class action', 'manufacturing controls', 'clinical trials'], 'insights': [{'ticker': 'JSPR', 'sentiment': 'negative', 'sentiment_reasoning': 'The lawsuit alleges the company made false statements about manufacturing procedures, regulatory compliance, and overstated business prospects, which potentially misled investors and caused financial damages'}, {'ticker': 'JSPRW', 'sentiment': 'negative', 'sentiment_reasoning': 'The lawsuit alleges the company made false statements about manufacturing procedures, regulatory compliance, and overstated business prospects, which potentially misled investors and caused financial damages'}], 'publisher.name': 'GlobeNewswire Inc.', 'publisher.homepage_url': 'https://www.globenewswire.com', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/globenewswire.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/globenewswire.ico', 'amp_url': nan}, {'id': '1b26ee6b521fb3390e0852ddb9053d910e58f56a6165afa12206c7016e701536', 'title': 'Capital Group Canada Announces Estimated 2025 Annual Capital Gains Distributions for Capital Group Canada ETFs (CAPG, CAPI, CAPM, CAPW)', 'author': 'Prnewswire', 'published_utc': '2025-10-31T21:30:00Z', 'article_url': 'https://www.benzinga.com/pressreleases/25/10/n48575878/capital-group-canada-announces-estimated-2025-annual-capital-gains-distributions-for-capital-group?utm_source=benzinga_taxonomy&utm_medium=rss_feed_free&utm_content=taxonomy_rss&utm_campaign=channel', 'tickers': ['CGCB'], 'image_url': 'https://www.benzinga.com/next-assets/images/benzinga-schema-image-default.png', 'description': 'Capital Group Canada released estimated annual reinvested capital gains distributions for its ETFs for the 2025 tax year, with final distributions to be announced in December and payable in January 2026.', 'keywords': ['ETFs', 'capital gains', 'distributions', 'tax year', 'investment'], 'insights': [{'ticker': 'CGCB', 'sentiment': 'neutral', 'sentiment_reasoning': 'Estimated distributions are part of standard annual financial reporting process with no indication of exceptional performance or challenges'}], 'publisher.name': 'Benzinga', 'publisher.homepage_url': 'https://www.benzinga.com/', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/benzinga.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/benzinga.ico', 'amp_url': nan}, {'id': 'c45000e9357bab55292e000cb8d97bf92de28278e5f1d6b8d07c8332dc724580', 'title': 'Caliber Launches Noteholder Debt-to-Equity Conversion Program and Completes First $1.9 Million Tranche', 'author': 'Caliber Investor Relations', 'published_utc': '2025-10-31T21:25:00Z', 'article_url': 'https://www.globenewswire.com/news-release/2025/10/31/3178675/0/en/Caliber-Launches-Noteholder-Debt-to-Equity-Conversion-Program-and-Completes-First-1-9-Million-Tranche.html', 'tickers': ['CWD', 'GLNK'], 'image_url': 'https://ml.globenewswire.com/Resource/Download/338edb26-153e-4b48-95eb-2738303fb4c7', 'description': 'Caliber announced a voluntary Noteholder Conversion Program allowing note holders to convert $3.0 million tranches of unsecured corporate notes into Class A common stock, completing an initial $1.9 million conversion to reduce leverage and improve financial flexibility.', 'keywords': ['debt conversion', 'equity', 'financial restructuring', 'balance sheet optimization'], 'insights': [{'ticker': 'CWD', 'sentiment': 'positive', 'sentiment_reasoning': 'The company is proactively reducing high-cost debt, eliminating annual interest expenses, strengthening its balance sheet, and positioning itself for potential profitability in 2026'}, {'ticker': 'GLNK', 'sentiment': 'neutral', 'sentiment_reasoning': \"Mentioned as part of Caliber's digital asset treasury strategy, with no significant positive or negative implications in this article\"}], 'publisher.name': 'GlobeNewswire Inc.', 'publisher.homepage_url': 'https://www.globenewswire.com', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/globenewswire.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/globenewswire.ico', 'amp_url': nan}, {'id': 'f454b54fa7f7c606181104a3d8c08f9b0d626795c35daac31d5d19cd364a85e4', 'title': 'Gran Tierra Announces Confirmation with Respect to Post-Offer Intention Statements Regarding i3 Energy plc', 'author': 'Globe Newswire', 'published_utc': '2025-10-31T21:21:00Z', 'article_url': 'https://www.benzinga.com/pressreleases/25/10/g48575763/gran-tierra-announces-confirmation-with-respect-to-post-offer-intention-statements-regarding-i3-en?utm_source=benzinga_taxonomy&utm_medium=rss_feed_free&utm_content=taxonomy_rss&utm_campaign=channel', 'tickers': ['GTE'], 'image_url': 'https://www.benzinga.com/next-assets/images/benzinga-schema-image-default.png', 'description': 'Gran Tierra Energy confirmed compliance with post-offer intention statements following its recommended cash and shares acquisition of i3 Energy, which was completed on October 31, 2024.', 'keywords': ['acquisition', 'takeover', 'scheme of arrangement', 'compliance'], 'insights': [{'ticker': 'GTE', 'sentiment': 'neutral', 'sentiment_reasoning': 'Company is reporting routine compliance with regulatory requirements after completing a previously announced acquisition, with no indication of significant positive or negative outcomes'}], 'publisher.name': 'Benzinga', 'publisher.homepage_url': 'https://www.benzinga.com/', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/benzinga.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/benzinga.ico', 'amp_url': nan}, {'id': '5bf11b738ec7881ca1e4bb34979062f1ed853d87eaa3acda5d0e851d1c584541', 'title': 'Dynamix Corporation III Completes $201.25 Million Initial Public Offering', 'author': 'Globe Newswire', 'published_utc': '2025-10-31T21:13:50Z', 'article_url': 'https://www.benzinga.com/pressreleases/25/10/g48575520/dynamix-corporation-iii-completes-201-25-million-initial-public-offering?utm_source=benzinga_taxonomy&utm_medium=rss_feed_free&utm_content=taxonomy_rss&utm_campaign=channel', 'tickers': ['COHN', 'ETHM', 'ETHMU', 'ETHMW'], 'image_url': 'https://www.benzinga.com/next-assets/images/benzinga-schema-image-default.png', 'description': 'Dynamix Corporation III successfully completed its initial public offering, raising $201.25 million by selling 20,125,000 units at $10.00 per unit on the Nasdaq Global Market under the ticker DNMXU.', 'keywords': ['IPO', 'SPAC', 'Nasdaq', 'energy infrastructure', 'digital infrastructure'], 'insights': [{'ticker': 'COHN', 'sentiment': 'neutral', 'sentiment_reasoning': 'Served as sole book-running manager for the IPO, performing a standard financial service role'}, {'ticker': 'ETHM', 'sentiment': 'positive', 'sentiment_reasoning': 'Successfully completed a large $201.25 million IPO, indicating strong market interest and potential for future business combinations in energy and digital infrastructure sectors'}, {'ticker': 'ETHMU', 'sentiment': 'positive', 'sentiment_reasoning': 'Successfully completed a large $201.25 million IPO, indicating strong market interest and potential for future business combinations in energy and digital infrastructure sectors'}, {'ticker': 'ETHMW', 'sentiment': 'positive', 'sentiment_reasoning': 'Successfully completed a large $201.25 million IPO, indicating strong market interest and potential for future business combinations in energy and digital infrastructure sectors'}], 'publisher.name': 'Benzinga', 'publisher.homepage_url': 'https://www.benzinga.com/', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/benzinga.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/benzinga.ico', 'amp_url': nan}, {'id': 'bb6873bc7b25e675f094c132d8e90014a9f1d49b203d1203f61a9888d1a62b77', 'title': \"Is Beyond Meat the Next Great Meme Stock? This Week's Performance Hints That the Party Could Be Over\", 'author': 'Jeremy Bowman', 'published_utc': '2025-10-31T21:05:00Z', 'article_url': 'https://www.fool.com/investing/2025/10/31/is-beyond-meat-the-next-great-meme-stock-this-week/?source=iedfolrf0000001', 'tickers': ['BYND', 'WMT', 'GME', 'GME.WS', 'AMC'], 'image_url': 'https://g.foolcdn.com/editorial/images/840517/beyond-meat-burger.jpeg', 'description': \"Beyond Meat experienced a dramatic stock surge of over 1,000% in October, driven by social media speculation and a debt-to-stock conversion, but the company's fundamental business challenges suggest the rally may be unsustainable.\", 'keywords': ['meme stock', 'short squeeze', 'plant-based meat', 'stock volatility'], 'insights': [{'ticker': 'BYND', 'sentiment': 'negative', 'sentiment_reasoning': 'Poor product-market fit, declining revenue, consistent losses, high debt, and inability to achieve profitable unit economics indicate significant business challenges'}, {'ticker': 'WMT', 'sentiment': 'neutral', 'sentiment_reasoning': 'Mentioned as expanding Beyond Meat product offerings, but no deep analysis provided'}, {'ticker': 'GME', 'sentiment': 'neutral', 'sentiment_reasoning': 'Used as a comparative example of a successful meme stock, but not directly analyzed'}, {'ticker': 'GME.WS', 'sentiment': 'neutral', 'sentiment_reasoning': 'Used as a comparative example of a successful meme stock, but not directly analyzed'}, {'ticker': 'AMC', 'sentiment': 'neutral', 'sentiment_reasoning': 'Used as another meme stock comparison, with no specific current analysis'}], 'publisher.name': 'The Motley Fool', 'publisher.homepage_url': 'https://www.fool.com/', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/themotleyfool.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/themotleyfool.ico', 'amp_url': nan}, {'id': '9df8c9443e1087ce64233eaa157c0f8567d68fe02b58c4e52dbe4cdb037d6946', 'title': 'Lucas GC Limited Announces 1H 2025 Financial Results: Revenue at US$54.01 million with Increases in Gross Margin', 'author': 'Howard Lee (Ceo)', 'published_utc': '2025-10-31T21:00:00Z', 'article_url': 'https://www.globenewswire.com/news-release/2025/10/31/3178664/0/en/Lucas-GC-Limited-Announces-1H-2025-Financial-Results-Revenue-at-US-54-01-million-with-Increases-in-Gross-Margin.html', 'tickers': ['LGCL'], 'image_url': 'https://ml.globenewswire.com/Resource/Download/cd92a9e2-678a-46e6-83aa-0b4e080ccaa6', 'description': 'Lucas GC Limited reported 1H 2025 revenue of US$54.01 million, a 36.11% decrease from the previous year, with improved gross margin of 33.74%. The company attributed revenue decline to economic slowdown and strategic refocus on higher-margin products.', 'keywords': ['AI', 'PaaS', 'financial results', 'technology', 'revenue', 'gross margin'], 'insights': [{'ticker': 'LGCL', 'sentiment': 'neutral', 'sentiment_reasoning': 'Despite revenue decrease, the company showed positive signs with increased gross margin, continued R&D investment, and strategic repositioning as a technology company'}], 'publisher.name': 'GlobeNewswire Inc.', 'publisher.homepage_url': 'https://www.globenewswire.com', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/globenewswire.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/globenewswire.ico', 'amp_url': nan}, {'id': '160900fb0066ae1d0651527050c25dd7ac8bd9a1ac07d2554d9163ed74375986', 'title': \"Skyharbour Announces Participation in Red Cloud's 2025 Fall Mining Showcase in Toronto\", 'author': 'Jordan Trimble', 'published_utc': '2025-10-31T21:00:00Z', 'article_url': 'https://www.globenewswire.com/news-release/2025/10/31/3178663/36591/en/Skyharbour-Announces-Participation-in-Red-Cloud-s-2025-Fall-Mining-Showcase-in-Toronto.html', 'tickers': ['DNN'], 'image_url': 'https://ml.globenewswire.com/Resource/Download/16423a4e-ffa9-4806-9254-b16d8f3ce465', 'description': \"Skyharbour Resources will present at Red Cloud's Fall Mining Showcase in Toronto and has engaged Plutus Invest and Consulting for marketing services in Europe, focusing on uranium exploration projects in Canada's Athabasca Basin.\", 'keywords': ['uranium', 'exploration', 'mining', 'Athabasca Basin', 'marketing'], 'insights': [{'ticker': 'DNN', 'sentiment': 'neutral', 'sentiment_reasoning': 'Mentioned as a strategic shareholder that sold a project to Skyharbour'}], 'publisher.name': 'GlobeNewswire Inc.', 'publisher.homepage_url': 'https://www.globenewswire.com', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/globenewswire.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/globenewswire.ico', 'amp_url': nan}, {'id': '400d3cbbfbd676f6f1cc089fc43434a0d515fea76a3c72fb0e7f44889c8c4af0', 'title': 'Middlesex Water Company Reports Third Quarter 2025 Earnings', 'author': 'Nadine Leslie, Chair, President And Ceo', 'published_utc': '2025-10-31T20:50:00Z', 'article_url': 'https://www.globenewswire.com/news-release/2025/10/31/3178662/8240/en/Middlesex-Water-Company-Reports-Third-Quarter-2025-Earnings.html', 'tickers': ['MSEX'], 'image_url': 'https://ml.globenewswire.com/Resource/Download/09680b6c-76a9-473a-9eaf-23a286d0a0a3', 'description': 'Middlesex Water Company reported Q3 2025 net income of $14.0 million with diluted EPS of $0.77, slightly lower than the same quarter in 2024. The company invested $72 million in infrastructure, acquired Pinewood Acres water utility assets, and increased its quarterly dividend by 5.88%.', 'keywords': ['water utility', 'infrastructure investment', 'dividend increase', 'earnings report'], 'insights': [{'ticker': 'MSEX', 'sentiment': 'neutral', 'sentiment_reasoning': 'Slight decrease in net income and EPS compared to previous year, but continued infrastructure investment and dividend increase indicate stable performance'}], 'publisher.name': 'GlobeNewswire Inc.', 'publisher.homepage_url': 'https://www.globenewswire.com', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/globenewswire.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/globenewswire.ico', 'amp_url': nan}, {'id': '92836a3e25722957bd8ee54094cd216526e204afaa40affe1761e9ea274f8e9e', 'title': 'Vor Bio Reports Inducement Grants Under Nasdaq Listing Rule 5635(c)(4)', 'author': 'Carl Mauch And Sarah Spencer', 'published_utc': '2025-10-31T20:30:00Z', 'article_url': 'https://www.globenewswire.com/news-release/2025/10/31/3178646/0/en/Vor-Bio-Reports-Inducement-Grants-Under-Nasdaq-Listing-Rule-5635-c-4.html', 'tickers': ['VOR'], 'image_url': 'https://ml.globenewswire.com/Resource/Download/dde67700-b1b4-40c4-b930-13bd71804762', 'description': 'Vor Bio granted stock options and restricted stock units to 20 newly hired employees on October 15, 2025, with options vesting over a four-year period and an exercise price of $30.22 per share.', 'keywords': ['stock options', 'RSUs', 'employment', 'biotechnology', 'inducement plan'], 'insights': [{'ticker': 'VOR', 'sentiment': 'positive', 'sentiment_reasoning': 'The company is expanding its workforce and offering competitive compensation packages, indicating growth and financial stability'}], 'publisher.name': 'GlobeNewswire Inc.', 'publisher.homepage_url': 'https://www.globenewswire.com', 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/globenewswire.svg', 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/globenewswire.ico', 'amp_url': nan}]\n"
     ]
    }
   ],
   "source": [
    "sample_json = all_news.head(10).to_dict(orient='records')\n",
    "# .to_json(orient='records', indent=2)\n",
    "print(sample_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6657335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'fbd05842ba119aa51c71df671c546137b0c395b70d735a94724698973036bd88',\n",
       " 'title': 'JSPR DEADLINE: ROSEN, SKILLED INVESTOR COUNSEL, Encourages Jasper Therapeutics, Inc. Investors with Losses in Excess of $100K to Secure Counsel Before Important Deadline in Securities Class Action â€“ JSPR',\n",
       " 'author': 'Rosen Law Firm',\n",
       " 'published_utc': '2025-10-31T21:38:00Z',\n",
       " 'article_url': 'https://www.globenewswire.com/news-release/2025/10/31/3178678/673/en/JSPR-DEADLINE-ROSEN-SKILLED-INVESTOR-COUNSEL-Encourages-Jasper-Therapeutics-Inc-Investors-with-Losses-in-Excess-of-100K-to-Secure-Counsel-Before-Important-Deadline-in-Securities-Cl.html',\n",
       " 'tickers': ['JSPR', 'JSPRW'],\n",
       " 'image_url': 'https://ml.globenewswire.com/Resource/Download/745335af-3a3a-4fb5-84c0-fdedc9adf092',\n",
       " 'description': 'Rosen Law Firm is pursuing a securities class action lawsuit against Therapeutics for allegedly making false and misleading statements about manufacturing controls and product prospects during the period of November 30, 2023 to July 3, 2025.',\n",
       " 'keywords': ['securities lawsuit',\n",
       "  'class action',\n",
       "  'manufacturing controls',\n",
       "  'clinical trials'],\n",
       " 'insights': [{'ticker': 'JSPR',\n",
       "   'sentiment': 'negative',\n",
       "   'sentiment_reasoning': 'The lawsuit alleges the company made false statements about manufacturing procedures, regulatory compliance, and overstated business prospects, which potentially misled investors and caused financial damages'},\n",
       "  {'ticker': 'JSPRW',\n",
       "   'sentiment': 'negative',\n",
       "   'sentiment_reasoning': 'The lawsuit alleges the company made false statements about manufacturing procedures, regulatory compliance, and overstated business prospects, which potentially misled investors and caused financial damages'}],\n",
       " 'publisher.name': 'GlobeNewswire Inc.',\n",
       " 'publisher.homepage_url': 'https://www.globenewswire.com',\n",
       " 'publisher.logo_url': 'https://s3.polygon.io/public/assets/news/logos/globenewswire.svg',\n",
       " 'publisher.favicon_url': 'https://s3.polygon.io/public/assets/news/favicons/globenewswire.ico',\n",
       " 'amp_url': nan}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b89498f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publisher.name\n",
       "GlobeNewswire Inc.           2183\n",
       "The Motley Fool              1493\n",
       "Benzinga                     1021\n",
       "Investing.com                 298\n",
       "Zacks Investment Research       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_news[\"publisher.name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf7f698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_news_json = all_news.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dfab1fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_news_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7034f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key features:\n",
    "\n",
    "#   1. No chunking needed - Each news article is already a discrete document\n",
    "#   2. Text search - Searches across title, description, keywords, author\n",
    "#   3. Exact ticker matching - Function to find articles with specific ticker in tickers field\n",
    "#   4. Multi-ticker support - Search for multiple tickers at once\n",
    "#   5. Date filtering - Can filter news by publication date\n",
    "#   6. Boosting - Title matches get higher priority than description\n",
    "\n",
    "#   Note on chunking:\n",
    "#   Unlike the podcast data (long markdown documents), news articles are already atomic units. Each article is a complete piece of information, so no chunking is\n",
    "#   needed. The tickers field already provides precise ticker associations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1658041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total news articles: 5000\n",
      "Fields per article: 15\n",
      "Sample article keys: ['id', 'title', 'author', 'published_utc', 'article_url', 'tickers', 'image_url', 'description', 'keywords', 'insights', 'publisher.name', 'publisher.homepage_url', 'publisher.logo_url', 'publisher.favicon_url', 'amp_url']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import minsearch\n",
    "from minsearch import Index\n",
    "\n",
    "# Step 1: Convert DataFrame to list of dicts (if not already done)\n",
    "news_documents = all_news.to_dict(orient='records')\n",
    "\n",
    "print(f\"Total news articles: {len(news_documents)}\")\n",
    "print(f\"Fields per article: {len(news_documents[0])}\")\n",
    "print(f\"Sample article keys: {list(news_documents[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac216de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting fields: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:00<00:00, 579836.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Preprocessing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "  # Step 2: Preprocess documents - convert list fields to strings\n",
    "print(\"\\nPreprocessing documents...\")\n",
    "for doc in tqdm(news_documents, desc=\"Converting fields\"):\n",
    "    # Convert list fields to comma-separated strings\n",
    "    if isinstance(doc.get('tickers'), list):\n",
    "        doc['tickers'] = ', '.join(doc['tickers'])\n",
    "\n",
    "    if isinstance(doc.get('keywords'), list):\n",
    "        doc['keywords'] = ', '.join(doc['keywords'])\n",
    "\n",
    "    # Ensure text fields are strings\n",
    "    for field in ['title', 'description', 'author']:\n",
    "        if doc.get(field) is None:\n",
    "            doc[field] = ''\n",
    "        elif not isinstance(doc.get(field), str):\n",
    "            doc[field] = str(doc[field])\n",
    "\n",
    "print(\"âœ“ Preprocessing complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2159811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building search index...\n",
      "âœ“ Index created with 5000 articles\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  # Step 3: Create Index with relevant text fields\n",
    "news_index = Index(\n",
    "    text_fields=[\"title\", \"description\", \"keywords\", \"author\", \"tickers\"],\n",
    "    keyword_fields=[\"published_utc\", \"publisher.name\"]\n",
    ")\n",
    "\n",
    "# Step 4: Fit the index with preprocessed documents\n",
    "print(\"\\nBuilding search index...\")\n",
    "news_index.fit(news_documents)\n",
    "print(f\"âœ“ Index created with {len(news_documents)} articles\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44c05e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Search function to retrieve news for a ticker\n",
    "def search_news_by_ticker(ticker, num_results=10):\n",
    "    \"\"\"\n",
    "      Search for news articles related to a specific ticker.\n",
    "      \n",
    "      Args:\n",
    "          ticker: Stock ticker symbol (e.g., 'TSLA', 'AAPL')\n",
    "          num_results: Number of results to return\n",
    "      \n",
    "      Returns:\n",
    "          List of news articles matching the ticker\n",
    "    \"\"\"\n",
    "    results = news_index.search(\n",
    "        query=ticker,\n",
    "        num_results=num_results,\n",
    "        boost_dict={\n",
    "              'tickers': 5.0,      # Highest boost for ticker field\n",
    "              'title': 3.0,         # High boost for title\n",
    "              'description': 1.5,   # Medium boost for description\n",
    "              'keywords': 1.0       # Standard boost for keywords\n",
    "          }\n",
    "      )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbcce91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Testing search for TSLA...\n",
      "======================================================================\n",
      "\n",
      "Found 5 news articles for TSLA:\n",
      "\n",
      "1. Tesla Q3 Deliveries Smash Estimates, But Wall Street Wasn't Impressed. What Gives?\n",
      "   Published: 2025-10-09T08:23:00Z\n",
      "   Tickers: TSLA\n",
      "   Description: Tesla reported nearly 497,100 vehicle deliveries in Q3, exceeding Wall Street estimates by 50,000 un...\n",
      "\n",
      "2. Should You Buy Tesla Stock Before Wednesday Afternoon?\n",
      "   Published: 2025-10-20T14:37:00Z\n",
      "   Tickers: TSLA\n",
      "   Description: Tesla prepares to report Q3 earnings amid declining revenue and challenges in the EV market, with an...\n",
      "\n",
      "3. Tesla's New Robotaxi-Ready Models Strengthen the Bull Case for the Stock\n",
      "   Published: 2025-10-09T07:10:00Z\n",
      "   Tickers: TSLA\n",
      "   Description: Tesla introduced new Standard trims for Model 3 and Model Y with prices under $40,000, featuring sel...\n",
      "\n",
      "4. Tesla Finds New Buyer For Unsold Cybertrucks: SpaceX, xAI Stepping In\n",
      "   Published: 2025-10-14T19:29:47Z\n",
      "   Tickers: TSLA\n",
      "   Description: Tesla is selling Cybertrucks to SpaceX and xAI due to low consumer demand, with annual deliveries ex...\n",
      "\n",
      "5. Here's What Tesla's Latest Big Move Means for Investors\n",
      "   Published: 2025-10-19T22:23:00Z\n",
      "   Tickers: TSLA\n",
      "   Description: Tesla introduced lower-priced versions of Model Y and Model 3 in response to the removal of federal ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "  # Step 6: Test - Get news for TSLA\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Testing search for TSLA...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "tsla_news = search_news_by_ticker(\"TSLA\", num_results=5)\n",
    "\n",
    "print(f\"\\nFound {len(tsla_news)} news articles for TSLA:\\n\")\n",
    "for i, article in enumerate(tsla_news, 1):\n",
    "    print(f\"{i}. {article['title']}\")\n",
    "    print(f\"   Published: {article['published_utc']}\")\n",
    "    print(f\"   Tickers: {article['tickers']}\")\n",
    "    print(f\"   Description: {article['description'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe632b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Get exact ticker matches (more precise)\n",
    "def get_news_by_exact_ticker(ticker, news_docs=news_documents):\n",
    "    \"\"\"\n",
    "    Get articles where ticker appears in the tickers field.\n",
    "    More precise than text search.\n",
    "    \"\"\"\n",
    "    matches = [\n",
    "        article for article in news_docs\n",
    "        if ticker in article.get('tickers', '')\n",
    "    ]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "979beb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exact ticker matches for TSLA: 133 articles ---\n"
     ]
    }
   ],
   "source": [
    "# Test exact match\n",
    "tsla_exact = get_news_by_exact_ticker(\"TSLA\")\n",
    "print(f\"\\n--- Exact ticker matches for TSLA: {len(tsla_exact)} articles ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1748461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Multi-ticker search with progress bar\n",
    "def search_multiple_tickers(tickers, num_results=20):\n",
    "    \"\"\"\n",
    "    Search for news mentioning any of the given tickers.\n",
    "    \"\"\"\n",
    "    all_results = {}\n",
    "    for ticker in tqdm(tickers, desc=\"Searching tickers\"):\n",
    "        results = search_news_by_ticker(ticker, num_results=num_results)\n",
    "        all_results[ticker] = results\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d76621cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Searching for MAG7 stocks...\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching tickers: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 267.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results summary:\n",
      "\n",
      "AAPL: 5 articles found\n",
      "  Latest: Every Apple (AAPL) Investor Should Keep an Eye on This Number...\n",
      "\n",
      "GOOGL: 5 articles found\n",
      "  Latest: Allied Announces Third-Quarter Results...\n",
      "\n",
      "META: 5 articles found\n",
      "  Latest: Should You Buy Meta Platforms Before Oct. 29?...\n",
      "\n",
      "MSFT: 5 articles found\n",
      "  Latest: Microsoft's New OpenAI Deal Could Be Its Smartest AI Move Yet...\n",
      "\n",
      "TSLA: 5 articles found\n",
      "  Latest: Tesla Q3 Deliveries Smash Estimates, But Wall Street Wasn't Impressed. What Give...\n",
      "\n",
      "AMZN: 5 articles found\n",
      "  Latest: 1 Reason Why Amazon (AMZN) Is the Ultimate Growth Stock to Buy With $1,000 Right...\n",
      "\n",
      "NVDA: 5 articles found\n",
      "  Latest: Think You Missed the Boat on Nvidia? Here's the No. 1 Reason It Could Keep Climb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Get news for MAG7 stocks\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Searching for MAG7 stocks...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mag7_tickers = [\"AAPL\", \"GOOGL\", \"META\", \"MSFT\", \"TSLA\", \"AMZN\", \"NVDA\"]\n",
    "mag7_news = search_multiple_tickers(mag7_tickers, num_results=5)\n",
    "\n",
    "print(\"\\nResults summary:\")\n",
    "for ticker, articles in mag7_news.items():\n",
    "    print(f\"\\n{ticker}: {len(articles)} articles found\")\n",
    "    if articles:\n",
    "        print(f\"  Latest: {articles[0]['title'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4934adb9",
   "metadata": {},
   "source": [
    "# Q3: Persistent vs. in-memory storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3cdd2",
   "metadata": {},
   "source": [
    "## Reco: Persistent Storage (SQLite + Periodic Updates)\n",
    "\n",
    "âœ… Persistent & Accumulative:\n",
    "  - SQLite stores all historical news\n",
    "  - Each run adds only new articles (no duplicates)\n",
    "  - Survives restarts/crashes\n",
    "  - Can query historical data\n",
    "\n",
    "  âœ… Efficient Updates:\n",
    "  - Only fetches news newer than what's in DB\n",
    "  - Respects API rate limits\n",
    "  - Fast incremental updates\n",
    "\n",
    "  âœ… Flexible Querying:\n",
    "  - SQL queries for complex filters\n",
    "  - Direct ticker lookups\n",
    "  - Date-range queries\n",
    "  - Can export to other tools\n",
    "\n",
    "  âœ… Scalable:\n",
    "  - SQLite handles millions of rows\n",
    "  - Indexed for fast queries\n",
    "  - Can migrate to PostgreSQL if needed\n",
    "\n",
    "  âœ… Easy Scheduling:\n",
    "**Cron job for daily updates (Linux/Mac)**\n",
    "\n",
    "  0 9 * * * cd /path/to/project && uv run python update_news.py\n",
    "\n",
    "**Or use Python scheduler**\n",
    "\n",
    "  import schedule\n",
    "  schedule.every().day.at(\"09:00\").do(update_and_search_workflow, POLYGON_API_KEY)\n",
    "\n",
    "  For your use case with regular updates: SQLite + minsearch is the sweet spot! ðŸŽ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code:\n",
    "# TODO: cache function calls in the db too for many tickers??\n",
    "\n",
    "#   import sqlite3\n",
    "#   import pandas as pd\n",
    "#   from datetime import datetime, timezone\n",
    "#   from pathlib import Path\n",
    "#   from tqdm import tqdm\n",
    "\n",
    "#   # Configuration\n",
    "#   DB_DIR = Path(\"data\")\n",
    "#   DB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "#   DB_FILE = DB_DIR / \"news_database.db\"\n",
    "\n",
    "#   class NewsDatabase:\n",
    "#       \"\"\"Persistent news storage with SQLite.\"\"\"\n",
    "\n",
    "#       def __init__(self, db_path=DB_FILE):\n",
    "#           self.db_path = db_path\n",
    "#           self.conn = sqlite3.connect(db_path)\n",
    "#           self._create_tables()\n",
    "\n",
    "#       def _create_tables(self):\n",
    "#           \"\"\"Create news table if it doesn't exist.\"\"\"\n",
    "#           self.conn.execute(\"\"\"\n",
    "#               CREATE TABLE IF NOT EXISTS news (\n",
    "#                   id TEXT PRIMARY KEY,\n",
    "#                   title TEXT,\n",
    "#                   author TEXT,\n",
    "#                   published_utc TEXT,\n",
    "#                   article_url TEXT,\n",
    "#                   tickers TEXT,\n",
    "#                   image_url TEXT,\n",
    "#                   description TEXT,\n",
    "#                   keywords TEXT,\n",
    "#                   publisher_name TEXT,\n",
    "#                   publisher_homepage_url TEXT,\n",
    "#                   publisher_logo_url TEXT,\n",
    "#                   publisher_favicon_url TEXT,\n",
    "#                   amp_url TEXT,\n",
    "#                   insights TEXT,\n",
    "#                   created_at TEXT DEFAULT CURRENT_TIMESTAMP\n",
    "#               )\n",
    "#           \"\"\")\n",
    "\n",
    "#           # Create index on published_utc for fast date queries\n",
    "#           self.conn.execute(\"\"\"\n",
    "#               CREATE INDEX IF NOT EXISTS idx_published_utc \n",
    "#               ON news(published_utc)\n",
    "#           \"\"\")\n",
    "\n",
    "#           # Create index on tickers for fast ticker searches\n",
    "#           self.conn.execute(\"\"\"\n",
    "#               CREATE INDEX IF NOT EXISTS idx_tickers \n",
    "#               ON news(tickers)\n",
    "#           \"\"\")\n",
    "\n",
    "#           self.conn.commit()\n",
    "\n",
    "#       def get_latest_news_date(self):\n",
    "#           \"\"\"Get the most recent news date in database.\"\"\"\n",
    "#           cursor = self.conn.execute(\"\"\"\n",
    "#               SELECT MAX(published_utc) FROM news\n",
    "#           \"\"\")\n",
    "#           result = cursor.fetchone()[0]\n",
    "#           return result if result else None\n",
    "\n",
    "#       def add_news(self, news_df):\n",
    "#           \"\"\"\n",
    "#           Add news articles to database (skip duplicates).\n",
    "          \n",
    "#           Args:\n",
    "#               news_df: DataFrame with news articles\n",
    "          \n",
    "#           Returns:\n",
    "#               Number of new articles added\n",
    "#           \"\"\"\n",
    "#           # Preprocess: convert lists to strings\n",
    "#           news_df = news_df.copy()\n",
    "\n",
    "#           for col in ['tickers', 'keywords']:\n",
    "#               if col in news_df.columns:\n",
    "#                   news_df[col] = news_df[col].apply(\n",
    "#                       lambda x: ', '.join(x) if isinstance(x, list) else str(x)\n",
    "#                   )\n",
    "\n",
    "#           # Flatten nested publisher fields\n",
    "#           if 'publisher.name' in news_df.columns:\n",
    "#               news_df['publisher_name'] = news_df['publisher.name']\n",
    "#               news_df['publisher_homepage_url'] = news_df['publisher.homepage_url']\n",
    "#               news_df['publisher_logo_url'] = news_df['publisher.logo_url']\n",
    "#               news_df['publisher_favicon_url'] = news_df['publisher.favicon_url']\n",
    "\n",
    "#           # Convert insights to JSON string if exists\n",
    "#           if 'insights' in news_df.columns:\n",
    "#               news_df['insights'] = news_df['insights'].apply(str)\n",
    "\n",
    "#           # Select relevant columns\n",
    "#           cols = [\n",
    "#               'id', 'title', 'author', 'published_utc', 'article_url',\n",
    "#               'tickers', 'image_url', 'description', 'keywords',\n",
    "#               'publisher_name', 'publisher_homepage_url',\n",
    "#               'publisher_logo_url', 'publisher_favicon_url',\n",
    "#               'amp_url', 'insights'\n",
    "#           ]\n",
    "\n",
    "#           news_to_insert = news_df[[c for c in cols if c in news_df.columns]]\n",
    "\n",
    "#           # Insert with conflict ignore (skip duplicates)\n",
    "#           initial_count = self.count_articles()\n",
    "#           news_to_insert.to_sql('news', self.conn, if_exists='append',\n",
    "#                                 index=False, method='multi')\n",
    "#           final_count = self.count_articles()\n",
    "\n",
    "#           new_articles = final_count - initial_count\n",
    "#           return new_articles\n",
    "\n",
    "#       def count_articles(self):\n",
    "#           \"\"\"Get total number of articles in database.\"\"\"\n",
    "#           cursor = self.conn.execute(\"SELECT COUNT(*) FROM news\")\n",
    "#           return cursor.fetchone()[0]\n",
    "\n",
    "#       def get_all_news(self):\n",
    "#           \"\"\"Load all news from database as DataFrame.\"\"\"\n",
    "#           return pd.read_sql_query(\"SELECT * FROM news\", self.conn)\n",
    "\n",
    "#       def get_news_by_ticker(self, ticker):\n",
    "#           \"\"\"Get news for a specific ticker.\"\"\"\n",
    "#           query = \"\"\"\n",
    "#               SELECT * FROM news \n",
    "#               WHERE tickers LIKE ? \n",
    "#               ORDER BY published_utc DESC\n",
    "#           \"\"\"\n",
    "#           return pd.read_sql_query(query, self.conn, params=[f'%{ticker}%'])\n",
    "\n",
    "#       def get_news_since(self, date):\n",
    "#           \"\"\"Get news published after a specific date.\"\"\"\n",
    "#           query = \"\"\"\n",
    "#               SELECT * FROM news \n",
    "#               WHERE published_utc > ? \n",
    "#               ORDER BY published_utc DESC\n",
    "#           \"\"\"\n",
    "#           return pd.read_sql_query(query, self.conn, params=[date])\n",
    "\n",
    "#       def close(self):\n",
    "#           \"\"\"Close database connection.\"\"\"\n",
    "#           self.conn.close()\n",
    "\n",
    "\n",
    "#   # Fetch and update workflow\n",
    "#   def fetch_and_update_news(api_key, db=None):\n",
    "#       \"\"\"\n",
    "#       Fetch new news and add to database.\n",
    "#       Only fetches news newer than what's already in DB.\n",
    "      \n",
    "#       Args:\n",
    "#           api_key: Polygon.io API key\n",
    "#           db: NewsDatabase instance (optional)\n",
    "      \n",
    "#       Returns:\n",
    "#           Number of new articles added\n",
    "#       \"\"\"\n",
    "#       if db is None:\n",
    "#           db = NewsDatabase()\n",
    "\n",
    "#       # Get latest date in database\n",
    "#       latest_date = db.get_latest_news_date()\n",
    "\n",
    "#       if latest_date:\n",
    "#           print(f\"ðŸ“… Latest news in DB: {latest_date}\")\n",
    "#           print(f\"ðŸ”„ Fetching news newer than {latest_date}...\")\n",
    "#           max_date = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')\n",
    "#       else:\n",
    "#           print(\"ðŸ“­ Database is empty. Fetching all available news...\")\n",
    "#           max_date = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')\n",
    "\n",
    "#       # Fetch news (your existing function)\n",
    "#       new_news = get_all_news(api_key=api_key, news_limit=1000, max_date=max_date)\n",
    "\n",
    "#       if len(new_news) == 0:\n",
    "#           print(\"âœ“ No new articles to add\")\n",
    "#           return 0\n",
    "\n",
    "#       # Filter out articles older than latest_date\n",
    "#       if latest_date:\n",
    "#           new_news = new_news[new_news['published_utc'] > latest_date]\n",
    "\n",
    "#       if len(new_news) == 0:\n",
    "#           print(\"âœ“ No new articles to add (all were older)\")\n",
    "#           return 0\n",
    "\n",
    "#       # Add to database\n",
    "#       print(f\"ðŸ’¾ Adding {len(new_news)} new articles to database...\")\n",
    "#       added_count = db.add_news(new_news)\n",
    "\n",
    "#       print(f\"âœ“ Added {added_count} new articles\")\n",
    "#       print(f\"ðŸ“Š Total articles in database: {db.count_articles()}\")\n",
    "\n",
    "#       return added_count\n",
    "\n",
    "\n",
    "#   # Build search index from database\n",
    "#   def build_search_index(db=None):\n",
    "#       \"\"\"\n",
    "#       Build minsearch index from database.\n",
    "#       Call this after updating database.\n",
    "#       \"\"\"\n",
    "#       if db is None:\n",
    "#           db = NewsDatabase()\n",
    "\n",
    "#       print(\"\\nðŸ” Building search index...\")\n",
    "\n",
    "#       # Load all news from database\n",
    "#       all_news_df = db.get_all_news()\n",
    "#       news_documents = all_news_df.to_dict(orient='records')\n",
    "\n",
    "#       # Preprocess for minsearch\n",
    "#       print(\"âš™ï¸ Preprocessing documents...\")\n",
    "#       for doc in tqdm(news_documents, desc=\"Processing\"):\n",
    "#           # Ensure strings (already done in DB but just in case)\n",
    "#           for field in ['title', 'description', 'author', 'tickers', 'keywords']:\n",
    "#               if doc.get(field) is None:\n",
    "#                   doc[field] = ''\n",
    "#               elif not isinstance(doc.get(field), str):\n",
    "#                   doc[field] = str(doc[field])\n",
    "\n",
    "#       # Create and fit index\n",
    "#       from minsearch import Index\n",
    "\n",
    "#       news_index = Index(\n",
    "#           text_fields=[\"title\", \"description\", \"keywords\", \"author\", \"tickers\"],\n",
    "#           keyword_fields=[\"published_utc\", \"publisher_name\"]\n",
    "#       )\n",
    "\n",
    "#       news_index.fit(news_documents)\n",
    "#       print(f\"âœ“ Search index built with {len(news_documents)} articles\")\n",
    "\n",
    "#       return news_index, news_documents\n",
    "\n",
    "\n",
    "#   # Main workflow for regular updates\n",
    "#   def update_and_search_workflow(api_key):\n",
    "#       \"\"\"\n",
    "#       Complete workflow: fetch new news, update DB, rebuild index.\n",
    "#       Run this daily/hourly via cron or scheduler.\n",
    "#       \"\"\"\n",
    "#       print(\"=\"*70)\n",
    "#       print(\"ðŸ“° NEWS UPDATE WORKFLOW\")\n",
    "#       print(\"=\"*70)\n",
    "\n",
    "#       # 1. Initialize database\n",
    "#       db = NewsDatabase()\n",
    "#       print(f\"\\nðŸ“Š Current database stats:\")\n",
    "#       print(f\"   Total articles: {db.count_articles()}\")\n",
    "\n",
    "#       # 2. Fetch and add new news\n",
    "#       added = fetch_and_update_news(api_key, db)\n",
    "\n",
    "#       # 3. Rebuild search index (if new articles added)\n",
    "#       if added > 0 or db.count_articles() > 0:\n",
    "#           news_index, news_documents = build_search_index(db)\n",
    "#       else:\n",
    "#           news_index, news_documents = None, []\n",
    "\n",
    "#       # 4. Close database\n",
    "#       db.close()\n",
    "\n",
    "#       print(\"\\nâœ“ Update workflow complete!\")\n",
    "#       print(\"=\"*70)\n",
    "\n",
    "#       return news_index, news_documents\n",
    "\n",
    "\n",
    "#   # Usage examples:\n",
    "\n",
    "#   # Run once to initialize\n",
    "#   news_index, news_documents = update_and_search_workflow(POLYGON_API_KEY)\n",
    "\n",
    "#   # Later - just run again to get updates\n",
    "#   # news_index, news_documents = update_and_search_workflow(POLYGON_API_KEY)\n",
    "\n",
    "#   # Search using the index\n",
    "#   def search_news_by_ticker(ticker, news_index, num_results=10):\n",
    "#       results = news_index.search(\n",
    "#           query=ticker,\n",
    "#           num_results=num_results,\n",
    "#           boost_dict={\n",
    "#               'tickers': 5.0,\n",
    "#               'title': 3.0,\n",
    "#               'description': 1.5\n",
    "#           }\n",
    "#       )\n",
    "#       return results\n",
    "\n",
    "#   # Query database directly\n",
    "#   db = NewsDatabase()\n",
    "#   tsla_news_df = db.get_news_by_ticker(\"TSLA\")\n",
    "#   print(f\"Found {len(tsla_news_df)} TSLA articles in database\")\n",
    "\n",
    "#   # Get recent news\n",
    "#   recent_news = db.get_news_since(\"2025-10-25T00:00:00Z\")\n",
    "#   print(f\"Found {len(recent_news)} articles since Oct 25\")\n",
    "\n",
    "#   db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d87208",
   "metadata": {},
   "source": [
    "# Part 2: Build a Summary Agent Using Wikipedia Pages`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47085b",
   "metadata": {},
   "source": [
    "# Q4: Framework and LLM Provider\n",
    "Answer: easiest option: \n",
    "  1. Framework: OpenAI Agents SDK - chosen for its simplicity and native tool calling\n",
    "  2. Provider: OpenAI with gpt-4o-mini for cost-effectiveness\n",
    "  3. Tools: Three financial analysis tools integrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef71fa6",
   "metadata": {},
   "source": [
    "# Q5: Agent Instructions (fetch and save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc6c31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from agents import Agent, Runner, function_tool\n",
    "import requests\n",
    "from typing import Optional\n",
    "from requests.exceptions import RequestException\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Tool 1: Fetch Web Page\n",
    "def fetch_url(url: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetch the textual content of a webpage using Jina Reader.\n",
    "      \n",
    "    Args:\n",
    "        url: The target URL to fetch content from (e.g., 'https://example.com')\n",
    "      \n",
    "    Returns:\n",
    "        The text content of the webpage, or None if an error occurred\n",
    "    \"\"\"\n",
    "    if not url or not isinstance(url, str):\n",
    "        raise ValueError(\"The 'url' parameter must be a non-empty string.\")\n",
    "\n",
    "    jina_reader_base_url = \"https://r.jina.ai/\"\n",
    "    jina_reader_url = jina_reader_base_url + url.lstrip(\"/\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(jina_reader_url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return response.content.decode(\"utf-8\")\n",
    "    except RequestException as e:\n",
    "        print(f\"Error fetching URL '{jina_reader_url}': {e}\")\n",
    "        return None\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Error decoding response from '{jina_reader_url}'.\")\n",
    "        return None     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6f8a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 2: Save Summary\n",
    "def save_summary(summary: str, filename: str = \"summary.txt\") -> dict:\n",
    "    \"\"\"\n",
    "    Save a text summary to a file in the summaries directory.\n",
    "      \n",
    "    Args:\n",
    "        summary: The text content to save\n",
    "        filename: Name of the file (default: summary.txt)\n",
    "      \n",
    "    Returns:\n",
    "        Dictionary with status and file path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create summaries directory if it doesn't exist\n",
    "        summaries_dir = Path(\"summaries\")\n",
    "        summaries_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Save summary to file\n",
    "        file_path = summaries_dir / filename\n",
    "\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(summary)\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"file_path\": str(file_path),\n",
    "            \"message\": f\"Summary saved to {file_path}\",\n",
    "            \"summary_length\": len(summary)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": f\"Failed to save summary: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b688ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent created with instructions\n",
      "âœ“ Tools available: ['fetch_url', 'save_summary']\n"
     ]
    }
   ],
   "source": [
    "  # ANSWER: Final Agent Instructions\n",
    "AGENT_INSTRUCTIONS = \"\"\"You are a helpful web research assistant.\n",
    "\n",
    "When a user asks \"What is this page about?\" followed by a URL:\n",
    "\n",
    "STEP 1: Use the fetch_url tool to retrieve the webpage content.\n",
    "  - Pass the complete URL to the tool\n",
    "  - Wait for the content to be fetched\n",
    "\n",
    "STEP 2: After receiving the content, read and analyze it carefully.\n",
    "  - Identify the main topic and key points\n",
    "  - Create a clear, concise summary (3-5 paragraphs)\n",
    "\n",
    "STEP 3: Use the save_summary tool to save your summary.\n",
    "  - Pass your written summary as the 'summary' parameter\n",
    "  - Use a descriptive filename based on the page topic (e.g., 'capybara_summary.txt')\n",
    "\n",
    "STEP 4: Confirm to the user that:\n",
    "  - The page content was fetched successfully\n",
    "  - Your summary of what the page is about\n",
    "  - The location where the summary was saved\n",
    "\n",
    "IMPORTANT:\n",
    "- Always use both tools in sequence: fetch_url first, then save_summary\n",
    "- Do not skip the save_summary step\n",
    "- Provide a helpful summary in your response even after saving\n",
    "- If fetch_url fails, explain the error and do not attempt to save\"\"\"\n",
    "\n",
    "# Create the agent with proper instructions\n",
    "web_research_agent = Agent(\n",
    "    name=\"Web Research Assistant\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    "    tools=[\n",
    "          function_tool(fetch_url),\n",
    "          function_tool(save_summary)\n",
    "      ]\n",
    ")\n",
    "\n",
    "print(\"âœ“ Agent created with instructions\")\n",
    "print(f\"âœ“ Tools available: {[tool.name for tool in web_research_agent.tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcd8c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "async def test_web_research(url: str):\n",
    "    \"\"\"\n",
    "    Test the web research agent with a URL.\n",
    "      \n",
    "    Args:\n",
    "        url: The URL to analyze\n",
    "    \"\"\"\n",
    "    query = f\"What is this page about? {url}\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    results = await Runner.run(\n",
    "        web_research_agent,\n",
    "        input=query,\n",
    "        max_turns=15\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Agent Response:\")\n",
    "    print(\"=\"*70)\n",
    "    print(results.final_output)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f0040730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Testing with Capybara Wikipedia page\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Query: What is this page about? https://en.wikipedia.org/wiki/Capybara\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Agent Response:\n",
      "======================================================================\n",
      "The page about capybaras on Wikipedia provides a comprehensive overview of this fascinating rodent species. Hereâ€™s a summary of the key points:\n",
      "\n",
      "The **capybara**, or greater capybara (*Hydrochoerus hydrochaeris*), is recognized as the largest living rodent and is native to South America. These creatures thrive in various habitats, including savannas and dense forests, but are particularly drawn to environments near water bodies. Known for their social behavior, capybaras often form large groups, varying from 10 to as many as 100 individuals. Their diet mainly includes grasses and aquatic plants, and they display unique feeding behaviors such as coprophagy, which allows them to extract maximum nutrients from their food.\n",
      "\n",
      "Capybaras are remarkable swimmers, able to stay submerged for up to five minutes, which helps them evade predators. They primarily graze on grasses, adapting their diet according to seasonal availability. While they are not considered threatened, their populations can be affected by hunting and habitat loss in some areas of South America. The meat of capybaras is consumed in certain cultures, particularly during religious observances like Lent.\n",
      "\n",
      "In terms of domestication, capybaras have gained popularity in urban areas and zoos, often featured in videos and memes due to their gentle demeanor and social nature, contributing to their charming image in popular culture. \n",
      "\n",
      "The summary has been successfully saved to the file: **[capybara_summary.txt](summaries/capybara_summary.txt)**.\n",
      "\n",
      "âœ“ Agent setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Testing with Capybara Wikipedia page\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Uncomment to run:\n",
    "results = await test_web_research(\"https://en.wikipedia.org/wiki/Capybara\")\n",
    "\n",
    "print(\"\\nâœ“ Agent setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0cc503",
   "metadata": {},
   "source": [
    "# Q6: Search Function with Multiple Document Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d2ec01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, function_tool\n",
    "import requests\n",
    "from typing import Optional, List, Dict, Any\n",
    "from requests.exceptions import RequestException\n",
    "from pathlib import Path\n",
    "from minsearch import Index\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Global storage for indexed documents\n",
    "indexed_documents = []\n",
    "search_index = None\n",
    "\n",
    "# Tool 1: Fetch and Index Web Pages\n",
    "def fetch_and_index_pages(urls: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fetch multiple web pages and add them to the search index.\n",
    "      \n",
    "    Args:\n",
    "        urls: List of URLs to fetch and index\n",
    "      \n",
    "    Returns:\n",
    "        Dictionary with indexing results\n",
    "    \"\"\"\n",
    "    global indexed_documents, search_index\n",
    "\n",
    "    jina_reader_base_url = \"https://r.jina.ai/\"\n",
    "    newly_indexed = 0\n",
    "    failed = []\n",
    "\n",
    "    print(f\"\\nðŸ“¥ Fetching and indexing {len(urls)} pages...\")\n",
    "\n",
    "    for url in tqdm(urls, desc=\"Indexing pages\"):\n",
    "        try:\n",
    "            # Fetch content\n",
    "            jina_url = jina_reader_base_url + url.lstrip(\"/\")\n",
    "            response = requests.get(jina_url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            content = response.content.decode(\"utf-8\")\n",
    "\n",
    "            # Create document\n",
    "            doc = {\n",
    "                'url': url,\n",
    "                'content': content,\n",
    "                'title': url.split('/')[-1].replace('_', ' ')\n",
    "            }\n",
    "\n",
    "            indexed_documents.append(doc)\n",
    "            newly_indexed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            failed.append({'url': url, 'error': str(e)})\n",
    "\n",
    "    # Rebuild search index\n",
    "    if indexed_documents:\n",
    "        search_index = Index(text_fields=['content', 'title', 'url'])\n",
    "        search_index.fit(indexed_documents)\n",
    "\n",
    "    return {\n",
    "        'status': 'success',\n",
    "        'newly_indexed': newly_indexed,\n",
    "        'total_documents': len(indexed_documents),\n",
    "        'failed': failed,\n",
    "        'message': f\"Successfully indexed {newly_indexed} pages. Total documents: {len(indexed_documents)}\"\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba0eda98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 2: Search Indexed Documents\n",
    "def search_documents(query: str, num_results: int = 3) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search through indexed documents for relevant information.\n",
    "      \n",
    "    Args:\n",
    "        query: Search query string\n",
    "        num_results: Number of results to return (default: 3)\n",
    "      \n",
    "    Returns:\n",
    "        Dictionary with search results and the query used\n",
    "    \"\"\"\n",
    "    global search_index, indexed_documents\n",
    "\n",
    "    if not search_index or not indexed_documents:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'message': 'No documents indexed. Please index documents first.',\n",
    "            'query_used': query,\n",
    "            'results': []\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        results = search_index.search(\n",
    "            query=query,\n",
    "            num_results=num_results,\n",
    "            boost_dict={'title': 2.0, 'content': 1.0}\n",
    "        )\n",
    "\n",
    "        # Format results with excerpts\n",
    "        formatted_results = []\n",
    "        for result in results:\n",
    "            # Get relevant excerpt (first 500 chars containing query terms)\n",
    "            content = result['content']\n",
    "            query_lower = query.lower()\n",
    "\n",
    "            # Find position of query terms in content\n",
    "            pos = content.lower().find(query_lower)\n",
    "            if pos == -1:\n",
    "                # If exact match not found, take first 500 chars\n",
    "                excerpt = content[:500]\n",
    "            else:\n",
    "                # Get context around the query\n",
    "                start = max(0, pos - 200)\n",
    "                end = min(len(content), pos + 300)\n",
    "                excerpt = content[start:end]\n",
    "\n",
    "            formatted_results.append({\n",
    "                'title': result['title'],\n",
    "                'url': result['url'],\n",
    "                'excerpt': excerpt + '...'\n",
    "            })\n",
    "\n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'query_used': query,\n",
    "            'num_results': len(formatted_results),\n",
    "            'results': formatted_results\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'message': f\"Search failed: {str(e)}\",\n",
    "            'query_used': query,\n",
    "            'results': []\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bed9c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 3: Save Summary (from Q5)\n",
    "def save_summary(summary: str, filename: str = \"summary.txt\") -> dict:\n",
    "    \"\"\"\n",
    "    Save a text summary to a file in the summaries directory.\n",
    "      \n",
    "    Args:\n",
    "        summary: The text content to save\n",
    "        filename: Name of the file (default: summary.txt)\n",
    "      \n",
    "    Returns:\n",
    "        Dictionary with status and file path\n",
    "    \"\"\"\n",
    "    try:\n",
    "        summaries_dir = Path(\"summaries\")\n",
    "        summaries_dir.mkdir(exist_ok=True)\n",
    "        file_path = summaries_dir / filename\n",
    "\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(summary)\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"file_path\": str(file_path),\n",
    "            \"message\": f\"Summary saved to {file_path}\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": f\"Failed to save summary: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bfbb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER: Enhanced Agent Instructions with Search\n",
    "SEARCH_AGENT_INSTRUCTIONS = \"\"\"You are a research assistant specializing in information retrieval and synthesis.\n",
    "\n",
    "  Your capabilities:\n",
    "  1. fetch_and_index_pages: Index web pages into a searchable database\n",
    "  2. search_documents: Search indexed documents for specific information\n",
    "  3. save_summary: Save your findings to a file\n",
    "\n",
    "  WORKFLOW FOR INDEXING MULTIPLE PAGES:\n",
    "  When asked to index multiple pages, use fetch_and_index_pages with ALL URLs in a single call.\n",
    "  Example: fetch_and_index_pages(urls=['url1', 'url2', 'url3', ...])\n",
    "\n",
    "  WORKFLOW FOR ANSWERING QUESTIONS:\n",
    "  When asked a question about indexed content:\n",
    "\n",
    "  STEP 1: Formulate 2-3 specific search queries related to the question.\n",
    "  - Break down the question into key concepts\n",
    "  - Create targeted search queries for each concept\n",
    "  - Example question: \"What are threats to capybara populations?\"\n",
    "    Search queries could be:\n",
    "    * \"threats capybara population\"\n",
    "    * \"capybara predators dangers\"\n",
    "    * \"capybara conservation habitat loss\"\n",
    "\n",
    "  STEP 2: Use search_documents for EACH search query.\n",
    "  - Call search_documents multiple times with different queries\n",
    "  - Collect information from all search results\n",
    "\n",
    "  STEP 3: Synthesize findings from all searches.\n",
    "  - Combine information from multiple search results\n",
    "  - Identify common themes and specific details\n",
    "  - Organize findings logically\n",
    "\n",
    "  STEP 4: Provide comprehensive answer to the user.\n",
    "  - List the search queries you used\n",
    "  - Summarize key findings\n",
    "  - Include specific details from the documents\n",
    "\n",
    "  IMPORTANT:\n",
    "  - ALWAYS use search_documents when asked a question about indexed content\n",
    "  - Use multiple different search queries to gather comprehensive information\n",
    "  - Show your search queries in the response so users know what you searched for\n",
    "  - Synthesize information from all results into a coherent answer\n",
    "  - If results are insufficient, try alternative search queries\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82389d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
